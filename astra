#!/bin/sh
# Astral v0.4.3 - minimal POSIX package manager for Astaraxia
# Features: Source-only, Auto-recipe fetch, Version locking, Build isolation,
#           Post-install/Pre-remove hooks, File conflict detection, SHA256 Checksums.

set -eu

# Directory Layout
RECIPES_DIR=${RECIPES_DIR:-/usr/src/astral/recipes}
CACHE_SRC=${CACHE_SRC:-/var/cache/astral/src}
CACHE_BIN=${CACHE_BIN:-/var/cache/astral/bin}
DB_DIR=${DB_DIR:-/var/lib/astral/db}
REPO_URL=${REPO_URL:-https://izumi-sonoka.github.io/Astral-Repo/}                                  # URL for index/metadata (GitHub Pages)
# Note: Keeping this definition without a trailing slash for cleanliness.
RECIPE_RAW_URL=${RECIPE_RAW_URL:-https://raw.githubusercontent.com/Izumi-Sonoka/Astral-Repo/main} # Base URL for raw recipe files
INDEX_FILE="$DB_DIR/index"
LOG_DIR=${LOG_DIR:-/var/log/astral}
SELF_UPDATE_URL=${SELF_UPDATE_URL:-https://raw.githubusercontent.com/Astaraxia-Linux/Astral/refs/heads/main/astral}
SELF_UPDATE_PATH=/usr/bin/astral
TMPDIR=${TMPDIR:-/tmp}

mkdir -p "$RECIPES_DIR" "$CACHE_SRC" "$CACHE_BIN" "$DB_DIR" "$LOG_DIR" "$TMPDIR"

err() { printf 'ERROR: %s\n' "$*" >&2; exit 1; }
info() { printf '%s\n' "$*"; }

usage() {
  cat <<USAGE
Usage: astral <command> [pkg...]
Commands:
  -s, --sync <pkg>        Download recipe (if missing), check deps, and install/upgrade.
  -comp, --compile <pkg>  Build from recipe and install (force build).
  -u, --update            Updates the remote package index (for search).
  --search <pkg>          Searches for package in local recipes and remote index.
  -R, --Remove <pkg>      Remove package (leave deps).
  -r, --RemoveDep <pkg>   Remove package and attempt to remove orphan deps.
  -Cc, --Clean-Cache      Remove recipes for packages that are NOT currently installed.
  -U, --self-update       Update the astral script itself from GitHub. **STILL IN WIP**
  --inspect <pkg>         Show recipe content.
  --list-installed        List installed packages.
USAGE
}

# --- CORE UTILITY FUNCTIONS ---

is_pkg_installed() {
  pkg="$1"
  [ -d "$DB_DIR/$pkg" ]
}

# helper: find recipe path
recipe_path() {
  pkg="$1"
  [ -f "$RECIPES_DIR/$pkg/build" ] && echo "$RECIPES_DIR/$pkg" && return 0
  [ -f "$RECIPES_DIR/$pkg.astral" ] && echo "$RECIPES_DIR/$pkg.astral" && return 0
  return 1
}

# Get installed version (returns "none" if not installed)
get_installed_ver() {
    local pkg="$1"
    if [ -f "$DB_DIR/$pkg/version" ]; then
        cat "$DB_DIR/$pkg/version"
    else
        echo "none"
    fi
}

create_meta() {
  pkg="$1"; ver="$2"; arch="$3"; dest="$4"
  cat > "$dest/.astral-meta" <<M
name=$pkg
version=$ver
arch=$arch
M
}

get_pkg_deps() {
    local pkg="$1"
    local depfile="$DB_DIR/$pkg/depends"
    [ -f "$depfile" ] || return 0
    cat "$depfile" | grep -v '^\s*#' | grep -v '^\s*$' | tr -d '[:space:]'
}

is_pkg_required() {
    local target_pkg="$1"
    for other_pkg_dir in "$DB_DIR"/*; do
        [ -d "$other_pkg_dir" ] || continue 
        local other_pkg=$(basename "$other_pkg_dir") 
        [ -z "$other_pkg" ] && continue
        [ "$other_pkg" = "$target_pkg" ] && continue
        if get_pkg_deps "$other_pkg" | grep -q "^${target_pkg}$"; then
            return 0 # Required
        fi
    done
    return 1 # Not required
}

# --- NETWORKING FUNCTIONS ---

# Fetch recipe files from remote (always syncs now to avoid stale recipes)
fetch_remote_recipe() {
    local pkg="$1"
    local local_dir="$RECIPES_DIR/$pkg"
    
    info "Attempting to fetch or refresh recipe for '$pkg' from remote..."
    
    # Create the directory 
    mkdir -p "$local_dir"

    local required_files="version build sources"
    # Added optional recipe files: checksums and conflicts
    local optional_files="depends package post_install post_remove checksums conflicts" 
    
    local clean_raw_url="${RECIPE_RAW_URL%/}"
    local remote_base="${clean_raw_url}/recipes/$pkg"

    for file in $required_files $optional_files; do
        local url="$remote_base/$file"
        local dest="$local_dir/$file"
        
        # Download silently (-s), fail on 404 (-f). Suppress curl's error output (2>/dev/null) 
        # and rely only on the exit code to determine success/failure.
        if curl -fsSL "$url" -o "$dest" 2>/dev/null; then
            :
        else
            # Check against mandatory files
            if echo "$required_files" | grep -q "$file"; then
                err "Failed to fetch mandatory file '$file' for package '$pkg' from $url"
                rm -rf "$local_dir"
                return 1
            fi
            # If optional file fails, just remove the old local copy
            rm -f "$dest"
        fi
    done
    
    # Make scripts executable
    chmod +x "$local_dir/build" 2>/dev/null || true 
    chmod +x "$local_dir/package" 2>/dev/null || true
    # Ensure hooks are executable
    chmod +x "$local_dir/post_install" 2>/dev/null || true
    chmod +x "$local_dir/post_remove" 2>/dev/null || true
    
    info "Recipe for '$pkg' refreshed successfully."
}

# Helper function to download and extract source archives
fetch_and_extract_sources() {
    local pkg="$1"
    local rpath="$2"
    local buildtmp="$3"
    
    local sources_file="$rpath/sources"
    [ -f "$sources_file" ] || return 0 # No sources to fetch

    info "Downloading $pkg source..."
    
    while IFS= read -r url; do
        url=$(echo "$url" | tr -d '[:space:]')
        [ -z "$url" ] && continue
        [ "${url:0:1}" = "#" ] && continue
        
        local filename=$(basename "$url")
        local dest_file="$buildtmp/$filename"
        
        info "  -> Downloading $filename"
        if curl -fsSL "$url" -o "$dest_file"; then
            : # Download successful, extraction happens later after checksum check
        else
            err "Failed to download source file from $url"
        fi
    done < "$sources_file"
}

# Verifies SHA256 checksums of downloaded source files.
verify_checksums() {
    local pkg="$1"
    local rpath="$2"
    local buildtmp="$3"
    
    local checksums_file="$rpath/checksums"
    [ -f "$checksums_file" ] || { info "No checksums provided for $pkg. Skipping integrity check."; return 0; }
    
    command -v sha256sum >/dev/null 2>&1 || err "sha256sum command not found. Cannot verify source integrity."

    info "Verifying source integrity using checksums..."
    
    while IFS= read -r line; do
        line=$(echo "$line" | tr -d '[:space:]')
        [ -z "$line" ] && continue
        [ "${line:0:1}" = "#" ] && continue
        
        # Expected format: <hash> <filename>
        local expected_hash=$(echo "$line" | awk '{print $1}')
        local filename=$(echo "$line" | awk '{print $2}')
        local file_path="$buildtmp/$filename"

        if [ ! -f "$file_path" ]; then
            err "Checksum error: Source file '$filename' not found in build directory. Cannot verify."
        fi

        # Use sha256sum to check integrity
        local actual_hash=$(sha256sum "$file_path" | awk '{print $1}')
        
        if [ "$actual_hash" != "$expected_hash" ]; then
            err "Checksum mismatch for $filename! Expected $expected_hash, got $actual_hash. Source may be corrupted or compromised. Aborting."
        else
            info "  -> Checksum verified for $filename."
        fi
    done < "$checksums_file"

    # Now that files are verified, extract them
    info "Checksums verified. Extracting sources..."
    local sources_file="$rpath/sources"
    
    while IFS= read -r url; do
        url=$(echo "$url" | tr -d '[:space:]')
        [ -z "$url" ] && continue
        [ "${url:0:1}" = "#" ] && continue
        
        local filename=$(basename "$url")
        local dest_file="$buildtmp/$filename"
        
        info "  -> Extracting $filename"
        # Attempt to extract common archive formats
        case "$filename" in
            *.tar.gz|*.tgz) tar -xf "$dest_file" -C "$buildtmp" || err "Tar extract failed for $filename" ;;
            *.tar.bz2|*.tbz) tar -xf "$dest_file" -C "$buildtmp" || err "Bzip2 extract failed for $filename" ;;
            *.tar.xz|*.txz) tar -xf "$dest_file" -C "$buildtmp" || err "XZ extract failed for $filename" ;;
            *.zip) unzip -q "$dest_file" -d "$buildtmp" || err "Unzip failed for $filename" ;;
            *) info "  -> Warning: Unknown archive type, skipping extraction for $filename." ;;
        esac
        rm "$dest_file" # Clean up the archive file
    done < "$sources_file"
}

# --- COMMAND IMPLEMENTATION FUNCTIONS ---

sync_pkg_recursive() {
    local pkg="$1"
    
    # 1. Ensure we have the recipe (Download/Refresh)
    fetch_remote_recipe "$pkg"

    local recipe_dir="$(recipe_path "$pkg")"
    [ -z "$recipe_dir" ] && err "Recipe for '$pkg' could not be found or downloaded."

    # 2. Handle Dependencies (Recursive)
    local depsf="$recipe_dir/depends"
    if [ -f "$depsf" ]; then
        info "Checking dependencies for $pkg..."
        while IFS= read -r dep_pkg; do
            dep_pkg=$(echo "$dep_pkg" | tr -d '[:space:]')
            if [ -z "$dep_pkg" ] || [ "${dep_pkg:0:1}" = "#" ]; then
                continue
            fi 
            sync_pkg_recursive "$dep_pkg"
        done < "$depsf"
    fi

    # 3. Build/Install (Version check happens inside build_from_recipe)
    build_from_recipe "$pkg"
}

build_from_recipe() {
    local pkg="$1"
    local rpath
    rpath=$(recipe_path "$pkg") || err "recipe $pkg not found"
    
    # --- VERSION CHECK LOGIC (Skip build if same version) ---
    local recipe_ver="unknown"
    [ -f "$rpath/version" ] && recipe_ver=$(cat "$rpath/version")
    
    local installed_ver=$(get_installed_ver "$pkg")
    
    if [ "$installed_ver" != "none" ]; then
        if [ "$installed_ver" = "$recipe_ver" ]; then
            info "Package '$pkg' is already installed at version $installed_ver. Up to date."
            return 0
        else
            info "Upgrading '$pkg' from $installed_ver to $recipe_ver..."
        fi
    else
        info "Installing '$pkg' version $recipe_ver..."
    fi
    # -----------------------------------------------------

    # build environment
    local buildtmp="$TMPDIR/astral-build-$pkg-$$"
    mkdir -p "$buildtmp"

    if [ -d "$rpath" ]; then
        cp -a "$rpath"/* "$buildtmp"/
    else
        cp -a "$rpath" "$buildtmp/recipe.astral"
    fi
    # IMPORTANT: CD into the temporary build directory after copying the files.
    cd "$buildtmp"

    # Set up a trap to ensure cleanup happens even if the script fails unexpectedly
    trap "rm -rf '$buildtmp'" EXIT 

    # 1. Fetch source code
    fetch_and_extract_sources "$pkg" "$rpath" "$buildtmp"
    
    # 2. Verify Checksums and Extract (moved extraction here)
    verify_checksums "$pkg" "$rpath" "$buildtmp"


    if [ -f "./build" ]; then
        chmod +x ./build || true
        local PKGDIR="$buildtmp/pkg"
        mkdir -p "$PKGDIR"
        
        # ISOLATED BUILD (Using DESTDIR)
        ( DESTDIR="$PKGDIR" ./build ) || err "build failed for $pkg" 
        
        # Make the ./package script optional
        if [ -f "./package" ]; then
            ( DESTDIR="$PKGDIR" PKGDIR="$PKGDIR" ./package ) || err "package() failed for $pkg"
        fi
        
        create_meta "$pkg" "$recipe_ver" "x86_64" "$PKGDIR"
        
        # Record file list for conflict check and database logging
        # The output of this command substitution is safe to pass unquoted into the heredoc 
        # as it is a list of paths separated by newlines.
        local new_files=$(tar -C "$PKGDIR" -tf . | grep -v '^\.$' | grep -v '^\.\/$' | grep -v '^\.astral-meta$' || true)

        # --- CONFLICT DETECTION (Feature: File overlap check + Metadata conflicts) ---
        info "Checking for package conflicts..."
        local conflicts_file="$rpath/conflicts"
        
        # A. Check Metadata Conflicts (Explicit conflicts defined in recipe)
        if [ -f "$conflicts_file" ]; then
            while IFS= read -r conflicting_pkg; do
                conflicting_pkg=$(echo "$conflicting_pkg" | tr -d '[:space:]')
                if is_pkg_installed "$conflicting_pkg"; then
                    err "Metadata conflict detected! Package '$pkg' conflicts with installed package '$conflicting_pkg'. Aborting installation."
                fi
            done < "$conflicts_file"
        fi

        # B. Check File Overlap Conflicts (Implicit conflicts by file)
        for installed_pkg_dir in "$DB_DIR"/*; do
            [ -d "$installed_pkg_dir" ] || continue
            installed_pkg_name=$(basename "$installed_pkg_dir")
            # If upgrading, skip conflict check against self
            [ "$installed_pkg_name" = "$pkg" ] && continue

            local existing_files="$installed_pkg_dir/files"
            [ -f "$existing_files" ] || continue

            # Loop through new files and check if any existing package owns it
            # Replacing complex here-doc with robust echo pipeline to avoid whitespace/EOF errors.
            echo "$new_files" | while IFS= read -r new_file; do
                if grep -q "^$new_file$" "$existing_files"; then
                    err "File conflict detected! $new_file is already owned by package '$installed_pkg_name'. Aborting installation."
                fi
            done
        done
        info "No critical package conflicts found."
        # --- END CONFLICT DETECTION ---


        info "Installing $pkg files to root filesystem..."
        
        # Install to / (Transactional extract)
        tar -C "$PKGDIR" -cf - . | tar -C / -xf - || err "failed to extract package files"
        
        # Record database
        local pkgdir="$DB_DIR/$pkg"
        mkdir -p "$pkgdir"
        printf '%s\n' "$recipe_ver" > "$pkgdir/version"
        printf '%s\n' "$new_files" > "$pkgdir/files"
        
        if [ -f "$buildtmp/depends" ]; then
            cp "$buildtmp/depends" "$pkgdir/depends"
        fi
        
        # --- POST-INSTALL HOOK ---
        if [ -f "$buildtmp/post_install" ]; then
            info "Running post_install hook for $pkg..."
            # Execute the hook script. PKGDIR is useful for accessing installed files relative to the staging dir (if needed)
            ( DESTDIR="/" PKGDIR="$PKGDIR" "$buildtmp/post_install" ) || info "Warning: post_install hook failed for $pkg. Continuing."
        fi
        # --- END HOOK ---
        
        info "Successfully installed $pkg ($recipe_ver)."
    else
        err "Recipe $pkg has no build script"
    fi
    
    # Cleanup will happen via the trap, but we can reset it if we reach here cleanly.
    trap - EXIT
    rm -rf "$buildtmp" # Manual cleanup if trap wasn't triggered
}

update_repo() {
    info "Updating package database index..."
    local INDEX_URL="${REPO_URL}astral.index"
    if curl -fsSL "$INDEX_URL" -o "$INDEX_FILE"; then
        info "Database updated successfully."
    else
        err "Failed to download index file from $INDEX_URL."
        return 1
    fi
}

search_pkg() {
    local query="$1"
    info "Searching for package '$query'..."
    info "--- Local Recipes ---"
    local found_local=0
    for r in "$RECIPES_DIR"/*; do
        if [ -d "$r" ]; then
            local pkg_name=$(basename "$r")
            if echo "$pkg_name" | grep -iq "$query"; then
                local ver="unknown"
                [ -f "$r/version" ] && ver=$(cat "$r/version")
                printf "L: %-20s (v%s)\n" "$pkg_name" "$ver"
                found_local=1
            fi
        fi
    done
    [ "$found_local" -eq 0 ] && info "No local recipes found."

    info "--- Remote Index ---"
    [ -f "$INDEX_FILE" ] || { info "Remote index not found. Run 'astral -u'."; return 0; }
    local found_remote=0
    while IFS= read -r line; do
        local pkg_name=$(echo "$line" | awk '{print $1}')
        local pkg_ver=$(echo "$line" | awk '{print $2}')
        if echo "$pkg_name" | grep -iq "$query"; then
            printf "R: %-20s (v%s)\n" "$pkg_name" "$pkg_ver"
            found_remote=1
        fi
    done < "$INDEX_FILE"
    [ "$found_remote" -eq 0 ] && info "No remote packages found."
}

self_update() {
    info "Starting astral self-update..."
    command -v curl >/dev/null 2>&1 || { err "curl not found."; return 1; }
    local tmp_file="$TMPDIR/astral-new.$$"
    if ! curl -fsSL "$SELF_UPDATE_URL" -o "$tmp_file"; then
        err "Failed to download new astral script."
        rm -f "$tmp_file"
        return 1
    fi
    if ! head -n 1 "$tmp_file" | grep -q '^#![[:space:]]*/bin/sh'; then
        err "Downloaded file invalid (missing shebang)."
        rm -f "$tmp_file"
        return 1
    fi
    chmod +x "$tmp_file"
    if mv -f "$tmp_file" "$SELF_UPDATE_PATH"; then
        info "Self-update successful!"
    else
        err "Failed to replace $SELF_UPDATE_PATH."
        rm -f "$tmp_file"
        return 1
    fi
}

remove_pkg() {
    pkg="$1"
    pkgdir="$DB_DIR/$pkg"
    [ -d "$pkgdir" ] || err "package $pkg not installed"

    # Set up a trap to clean up the temporary directory list file
    local dirs_file="$TMPDIR/astral-dirs-$pkg-$$"
    trap "rm -f '$dirs_file'" EXIT 

    # --- PRE-REMOVE HOOK ---
    local rpath=$(recipe_path "$pkg")
    if [ -f "$rpath/post_remove" ]; then
        info "Running post_remove hook for $pkg..."
        ( "$rpath/post_remove" ) || info "Warning: post_remove hook failed for $pkg, continuing removal."
    fi
    # --- END HOOK ---

    info "Removing $pkg"
    
    # 1. Read files list, remove files, and collect directories in the temporary file
    while IFS= read -r f; do
        [ -z "$f" ] && continue
        
        local fullpath="/$f"
        
        if [ -d "$fullpath" ]; then
            # Directory found. Add to the temporary list.
            printf "%s\n" "$f" >> "$dirs_file"
        elif [ -e "$fullpath" ]; then
            # File or symlink. Remove it immediately.
            info "  -> Deleting file: $fullpath"
            rm -f "$fullpath"
        else
            # Path doesn't exist, skip it.
            : 
        fi
    done < "$pkgdir/files"
    
    # 2. Process collected directories (deepest first, guaranteed by 'sort -r')
    if [ -f "$dirs_file" ]; then
        info "Attempting to clean up empty directories installed by $pkg..."
        # Sort reverse alphabetically to approximate deepest-first removal.
        sort -r "$dirs_file" | while IFS= read -r d; do
            [ -z "$d" ] && continue
            # rmdir will fail safely on non-empty directories
            if rmdir "/$d" 2>/dev/null; then
                info "  -> Deleted empty directory: /$d"
            fi
        done
        rm -f "$dirs_file" # Explicit cleanup
    fi
    
    # Reset trap before final deletion
    trap - EXIT
    rm -rf "$pkgdir"
    info "Removed $pkg successfully from database."
}

removedep_pkg() {
    pkg="$1"
    remove_pkg "$pkg"
    info "Scanning for orphaned dependencies..."
    while true; do
        found_orphan=0
        for dep_dir in "$DB_DIR"/*; do
            [ -d "$dep_dir" ] || continue
            dep_name=$(basename "$dep_dir")
            if ! is_pkg_required "$dep_name"; then
                info "Removing orphan dependency: $dep_name"
                remove_pkg "$dep_name"
                found_orphan=1
                break
            fi 
        done
        [ "$found_orphan" -eq 0 ] && break
    done
}

clean_cache() {
    info "Starting recipe cache cleanup in $RECIPES_DIR..."
    local cleaned_count=0
    for recipe_dir in "$RECIPES_DIR"/*; do
        if [ ! -d "$recipe_dir" ]; then
            continue
        fi
        local pkg=$(basename "$recipe_dir")
        
        if is_pkg_installed "$pkg"; then
            info "Recipe for '$pkg' is installed. Skipping."
        else
            info "Recipe for '$pkg' is NOT installed. Removing cache files..."
            rm -rf "$recipe_dir"
            cleaned_count=$((cleaned_count + 1))
        fi
    done
    info "Cache cleanup complete. Removed $cleaned_count orphaned recipe(s)."
}

list_installed() {
  for d in "$DB_DIR"/*; do
    [ -d "$d" ] || continue
    printf '%s %s\n' "$(basename "$d")" "$(cat "$d/version" 2>/dev/null || echo unknown)"
  done
}

# CLI dispatch
if [ $# -lt 1 ]; then usage; exit 1; fi

case "$1" in
  -s|--sync)
    [ $# -gt 1 ] || err "pkg required"
    sync_pkg_recursive "$2"
    ;;
  -comp|--compile)
    [ $# -gt 1 ] || err "pkg required"
    build_from_recipe "$2"
    ;;
  -u|--update)
    update_repo
    ;;
  --search)
    [ $# -gt 1 ] || err "package name required"
    search_pkg "$2"
    ;;
  -R|--Remove)
    [ $# -gt 1 ] || err "pkg required"
    remove_pkg "$2"
    ;;
  -r|--RemoveDep)
    [ $# -gt 1 ] || err "pkg required"
    removedep_pkg "$2"
    ;;
  -Cc|--Clean-Cache)
    clean_cache
    ;;
  -U|--self-update)
    self_update
    ;;
  -y|--All)
    info "Listing installed packages."
    list_installed
    ;;
  --inspect)
    [ $# -gt 1 ] || err "pkg required"
    r=$(recipe_path "$2") || err "recipe not found"
    if [ -d "$r" ]; then
      ls -la "$r"
      [ -f "$r/build" ] && sed -n '1,200p' "$r/build"
    else
      sed -n '1,200p' "$r"
    fi
    ;;
  --list-installed)
    list_installed
    ;;
  *)
    usage
    ;;
esac

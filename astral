#!/bin/sh
# Astral v4.0.0.0 Main - minimal POSIX package manager for Astaraxia
# ROLLBACKSSS (now my back can roll)
# V: 4 - Major . 0 - Minor . 0 - Patches . 0 - hotfixes

version="4.0.0.0 Main"

# Set strict execution environment, meow~
set -eu

# Global state variables
INSTALL_ROOT="/"    # Installation target directory
FORCE_BUILD=0
DRY_RUN=0
VISITED_PACKAGES=""

# Locate where tf is astral
SCRIPT_PATH="$(readlink -f "$0")"
SCRIPT_DIR="$(dirname "$SCRIPT_PATH")"

# Directory Layout
RECIPES_DIR=${RECIPES_DIR:-/usr/src/astral/recipes}
CACHE_SRC=${CACHE_SRC:-/var/cache/astral/src}
CACHE_BIN=${CACHE_BIN:-/var/cache/astral/bin}
DB_DIR=${DB_DIR:-/var/lib/astral/db}
WORLD_FILE="$DB_DIR/world"
WORLD_SET_FILE="$DB_DIR/world_set"
INDEX_FILE="$DB_DIR/index"
LOG_DIR=${LOG_DIR:-/var/log/astral}

# --- REPOS ---
REPO_URL=${REPO_URL:-https://izumi-sonoka.github.io/AOHARU/}
RECIPE_RAW_URL=${RECIPE_RAW_URL:-https://raw.githubusercontent.com/Izumi-Sonoka/AOHARU/main}
USER_REPO_URL=${USER_REPO_URL:-https://codeberg.org/Izumi/ASURA/raw/branch/main}
USER_RECIPE_RAW_URL=${USER_RECIPE_RAW_URL:-$USER_REPO_URL}

# --- SELF-UPDATE URLs ---
SELF_UPDATE_URL_MAIN=${SELF_UPDATE_URL_MAIN:-https://raw.githubusercontent.com/Astaraxia-Linux/Astral/refs/heads/main/astral}
SELF_UPDATE_URL_CUTTING_EDGE=${SELF_UPDATE_URL_CUTTING_EDGE:-https://raw.githubusercontent.com/Astaraxia-Linux/Astral/refs/heads/Testing/astra}
SELF_UPDATE_URL_BLEEDING_EDGE=${SELF_UPDATE_URL_BLEEDING_EDGE:-https://raw.githubusercontent.com/Astaraxia-Linux/Astral/refs/heads/Testing/astral}
SELF_UPDATE_PATH=/usr/bin/astral
TMPDIR=${TMPDIR:-/tmp}

# --- INDEKS --- Malay cuz why not
INDEX_FILE_AOHARU="$DB_DIR/index_aoharu"
INDEX_FILE_ASURA="$DB_DIR/index_asura"

# --- Misc Var ---
LOCK_FILE=${LOCK_FILE:-/var/lock/astral.lock}

mkdir -p "$RECIPES_DIR" "$CACHE_SRC" "$CACHE_BIN" "$DB_DIR" "$LOG_DIR" "$TMPDIR"

err() { printf 'ERROR: %s\n' "$*" >&2; exit 1; }
info() { printf '%s\n' "$*"; }
warn() { printf 'WARNING: %s\n' "$*" >&2; }

# --- REPOSITORY CONTEXT ---
REPO_CONTEXT="aoharu"  # Current repository context (aoharu or asura)
EXPLICIT_PKG_REPO=""   # Track which repo the main package came from

# version was here:

# --- CONFIG SYSTEM () ---
ASTRAL_STORE=${ASTRAL_STORE:-/var/lib/astral/store}
ASTRAL_PROFILES=${ASTRAL_PROFILES:-/var/lib/astral/profiles}
ASTRAL_GENERATIONS="$ASTRAL_PROFILES/.generations"
USE_STORE_MODE=${USE_STORE_MODE:-yes}  # Toggle for testing
mkdir -p "$ASTRAL_STORE" "$ASTRAL_PROFILES"
CONFIG_FILE=${CONFIG_FILE:-/etc/astral/make.conf}
VIRTUALS_DIR=${VIRTUALS_DIR:-/etc/astral/virtuals}
mkdir -p "$VIRTUALS_DIR"
MASK_FILE=${MASK_FILE:-/etc/astral/package.mask}
USE_FLAGS=""
CFLAGS="-O2 -pipe"
CXXFLAGS=""
LDFLAGS=""
MAKEFLAGS="-j1"
CCACHE_ENABLED="no"
FEATURES=""
BINPKG_ENABLED="no"
HOST_PROVIDED=${HOST_PROVIDED:-""}
CACHE_BIN=${CACHE_BIN:-/var/cache/astral/bin}

load_config() {
    if [ -f "$CONFIG_FILE" ]; then
        . "$CONFIG_FILE"
    fi

    [ -z "$CXXFLAGS" ] && CXXFLAGS="$CFLAGS"

    # Enhanced ccache support
    if [ "$CCACHE_ENABLED" = "yes" ]; then
        if command -v ccache >/dev/null 2>&1; then
            # Set ccache directory
            export CCACHE_DIR="${CCACHE_DIR:-/var/cache/ccache}"
            mkdir -p "$CCACHE_DIR" 2>/dev/null || true

            # Configure ccache
            export CCACHE_MAXSIZE="${CCACHE_MAXSIZE:-5G}"
            export CCACHE_COMPRESS="${CCACHE_COMPRESS:-true}"
            export CCACHE_COMPRESSLEVEL="${CCACHE_COMPRESSLEVEL:-6}"

            # Wrapper approach (more reliable)
            if [ -d "/usr/lib/ccache/bin" ]; then
                export PATH="/usr/lib/ccache/bin:$PATH"
                info "ccache enabled (wrapper mode, cache: $CCACHE_DIR)"
            else
                # Fallback to direct wrapping
                export CC="ccache gcc"
                export CXX="ccache g++"
                info "ccache enabled (direct mode, cache: $CCACHE_DIR)"
            fi
        else
            # Only warn if not installing ccache itself (check via environment variable)
            if [ "${INSTALLING_CCACHE:-0}" != "1" ]; then
                warn "CCACHE_ENABLED=yes but ccache not found. Install: astral -S dev-util/ccache"
            fi
        fi
    fi

    export CFLAGS CXXFLAGS LDFLAGS MAKEFLAGS
}

has_feature() {
    feature="$1"
    case " $FEATURES " in
        *" $feature "*) return 0 ;;
        *) return 1 ;;
    esac
}

sanitize_pkg_name() {
    pkg="$1"
    # Remove path traversal and dangerous characters
    echo "$pkg" | sed 's|/\.\./||g; s|^\.\./||g; s|/\./||g; s|^\./||g' | grep -v '\.\.' || err "Invalid package name: $pkg"
}

ensure_default_config() {
    if [ ! -f "$CONFIG_FILE" ]; then
        mkdir -p "$(dirname "$CONFIG_FILE")"
        cat > "$CONFIG_FILE" <<EOF
# Astral/make.conf configuration

# Build flags
USE_FLAGS=""
CFLAGS="-O2 -pipe -march=native"
CXXFLAGS=""
LDFLAGS="-Wl,--as-needed"
MAKEFLAGS="-j$(nproc)"

# ccache configuration
CCACHE_ENABLED="yes"
CCACHE_DIR="/var/cache/ccache"
CCACHE_MAXSIZE="5G"
CCACHE_COMPRESS="true"
CCACHE_COMPRESSLEVEL="6"

# Features
FEATURES="ccache parallel-make strip"
BINPKG_ENABLED="no"

# Binary stripping
STRIP_BINARIES="yes"     # Strip executables
STRIP_LIBS="yes"         # Strip shared libraries
STRIP_STATIC="yes"       # Strip static libraries

# Collision detection
COLLISION_DETECT="yes"   # Detect file collisions
GHOST_FILE_CHECK="yes"   # Check for files installed outside \$PKGDIR

# Dependency overrides
HOST_PROVIDED="gcc make libc glibc linux-headers"

# Store-based package management
USE_STORE_MODE="no"          # Enable store-based installation
ASTRAL_STORE="/var/lib/astral/store"
ASTRAL_PROFILES="/var/lib/astral/profiles"
EOF
    fi
}

ensure_default_virtuals() {
    if [ ! -d "$VIRTUALS_DIR" ] || [ -z "$(ls -A "$VIRTUALS_DIR" 2>/dev/null)" ]; then
        mkdir -p "$VIRTUALS_DIR"

        # Virtual: C compiler
        cat > "$VIRTUALS_DIR/compiler" <<EOF
# Virtual: C compiler
# Provided by: gcc, clang, tcc
gcc
clang
tcc
EOF

        # Virtual: libc
        cat > "$VIRTUALS_DIR/libc" <<EOF
# Virtual: C library
# Provided by: glibc, musl, uclibc
glibc
musl
uclibc
EOF

        # Virtual: text editor
        cat > "$VIRTUALS_DIR/editor" <<EOF
# Virtual: Text editor
nano
vim
emacs
ed
EOF
    fi
}

check_virtual() {
    dep="$1"

    # Check if this is a virtual package request
    if [ -f "$VIRTUALS_DIR/$dep" ]; then
        info "Checking virtual package: $dep"

        # Check if ANY provider is installed or host-provided
        while IFS= read -r provider; do
            # Strip whitespace
            provider=$(printf '%s' "$provider" | sed 's/^[[:space:]]*//; s/[[:space:]]*$//')
            [ -z "$provider" ] && continue

            # Skip comments
            case "$provider" in \#*) continue ;; esac

            # Check installed packages first
            if is_pkg_installed "$provider"; then
                info "  ✓ Virtual '$dep' satisfied by installed package: $provider"
                return 0
            fi

            # Then check host-provided (with improved detection)
            if check_host_dependency "$provider"; then
                info "  ✓ Virtual '$dep' satisfied by host: $provider"
                return 0
            fi
        done < "$VIRTUALS_DIR/$dep"

        # No provider found
        warn "Virtual '$dep' not satisfied by any provider"
        return 1
    fi

    return 1
}

ensure_default_mask() {
    if [ ! -f "$MASK_FILE" ]; then
        mkdir -p "$(dirname "$MASK_FILE")"
        cat > "$MASK_FILE" <<EOF
# Astral Package Mask File
#
# Syntax:
#   package-name              # Mask all versions
#   package-name >= 2.0       # Mask versions >= 2.0
#   package-name < 1.5        # Mask versions < 1.5
#
# Examples:
#   broken-package
#   experimental-tool >= 3.0
#   old-library < 2.0

# Add your masks below:
EOF
    fi
}

# Check if package version is masked
is_masked() {
    pkg="$1"
    ver="${2:-}"

    [ ! -f "$MASK_FILE" ] && return 1

    while IFS= read -r line; do
        line=$(printf '%s' "$line" | sed 's/^[[:space:]]*//; s/[[:space:]]*$//')
        [ -z "$line" ] && continue
        case "$line" in \#*) continue ;; esac

        mask_pkg=$(printf '%s' "$line" | awk '{print $1}')
        mask_op=$(printf '%s' "$line" | awk '{print $2}')
        mask_ver=$(printf '%s' "$line" | awk '{print $3}')

        # Check if package name matches
        if [ "$mask_pkg" = "$pkg" ]; then
            # No version constraint = mask all versions
            if [ -z "$mask_op" ]; then
                return 0
            fi

            # Check version constraint
            if [ -n "$ver" ] && [ -n "$mask_ver" ]; then
                if version_compare "$ver" "$mask_op" "$mask_ver"; then
                    return 0
                fi
            fi
        fi
    done < "$MASK_FILE"

    return 1
}

check_script_safety() {
    script_file="$1"
    pkg_name="$2"

    [ ! -f "$script_file" ] && return 0

    cat >&2 <<SAFETY_WARNING
═══════════════════════════════════════════════════════════════
⚠️  SAFETY CHECK: $pkg_name
═══════════════════════════════════════════════════════════════
WARNING: These checks provide BASIC protection only.
They can be bypassed by determined attackers.

DO NOT run untrusted packages without review.
Astral is NOT a security sandbox.

YOU HAVE BEEN WARNED
═══════════════════════════════════════════════════════════════
SAFETY_WARNING

    info "Running safety checks on '$pkg_name'..."

    # Blocks: rm -rf $PKGDIR/ or rm -rf $DESTDIR/
    if grep -qE '\$(\{)?(PKGDIR|DESTDIR)(\})?[[:space:]]*/[[:space:]]*$' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - unsafe PKGDIR usage detected (expands to /)"
    fi

    # Dangerous command patterns
    if grep -qE 'rm[[:space:]]+-[rf][rf][[:space:]]+(\$(\{)?(PKGDIR|DESTDIR)(\})?)?/[[:space:]]*$' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - dangerous rm -rf / detected"
    fi

    if grep -qE 'rm[[:space:]]+-[rf][rf][[:space:]]+/($|[^a-zA-Z])' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - rm -rf on root paths detected"
    fi

    # Block disk destruction commands
    if grep -qE '>[[:space:]]*/dev/sd|dd[[:space:]]+.*of=/dev/[sh]d|mkfs\.|wipefs' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - disk destruction command detected"
    fi

    # Block fork bombs
    if grep -qE ':[[:space:]]*\(\)[[:space:]]*\{[[:space:]]*:[[:space:]]*\|:[[:space:]]*&[[:space:]]*\}' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - fork bomb detected"
    fi

    # Block recursive chmod 777
    if grep -qE 'chmod[[:space:]]+-R[[:space:]]+777[[:space:]]+/' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - recursive chmod 777 on root detected"
    fi

    # Block curl|sh and wget|sh
    if grep -qE '(curl|wget).*\|[[:space:]]*(ba)?sh' "$script_file" 2>/dev/null; then
        err "SECURITY: Refusing to run '$pkg_name' - curl/wget piped to shell detected"
    fi

    # Warn about eval (not blocked, just warned)
    if grep -qE '^[[:space:]]*eval[[:space:]]' "$script_file" 2>/dev/null; then
        warn "Script '$pkg_name' contains 'eval' - review carefully before running"
    fi

    info "✓ Basic safety checks passed (review script manually for full safety)"
}

# --- FILE OWNERSHIP DATABASE ---
check_file_conflicts() {
    pkg="$1"
    pkgdir="$2"
    force="$3"

    conflict_file="$TMPDIR/conflicts.$$"

    [ "$DRY_RUN" -eq 1 ] && info "[DRY-RUN] Checking for file conflicts..."
    [ "$DRY_RUN" -eq 0 ] && info "Checking for file conflicts..."

    [ ! -d "$pkgdir" ] && return 0

    conflicts=""
    conflict_count=0

    ( cd "$pkgdir" && find . -type f -o -type l ) | sed 's|^\./||' | while IFS= read -r file; do
        [ -z "$file" ] && continue
        [ "$file" = ".astral-meta" ] && continue

        target_path="$INSTALL_ROOT/$file"

        # Skip if file doesn't exist yet
        [ ! -e "$target_path" ] && [ ! -L "$target_path" ] && continue

        # Check who owns this file
        owner=$(get_file_owner "$file") || owner=""

        if [ -n "$owner" ]; then
            owner_name=$(basename "$owner")
            if [ "$owner_name" != "$pkg" ]; then
                conflict_count=$((conflict_count + 1))
                warn "  ✗ CONFLICT: $file (owned by $owner)"
                printf '%s|%s\n' "$file" "$owner"
            fi
        else
            # File exists but not tracked
            conflict_count=$((conflict_count + 1))
            warn "  ✗ CONFLICT: $file (untracked file on system)"
            printf '%s|%s\n' "$file" "UNTRACKED"
        fi
    done > "$TMPDIR/conflicts.$$"

    conflict_count=$(wc -l < "$TMPDIR/conflicts.$$" 2>/dev/null || echo 0)
    if [ "$conflict_count" -gt 0 ]; then
        if [ "$force" -eq 0 ]; then
            cat "$TMPDIR/conflicts.$$" >&2
            rm -f "$TMPDIR/conflicts.$$"
            err "Found $conflict_count file conflict(s). Use -f/--force to override."
        else
            warn "Overriding $conflict_count file conflict(s) due to --force"
            cat "$TMPDIR/conflicts.$$" >&2
        fi
    else
        info "  ✓ No file conflicts detected"
    fi

    rm -f "$TMPDIR/conflicts.$$"
}

# --- VERSION COMPARISON ---
version_compare() {
    ver1="$1"
    op="$2"
    ver2="$3"

    # Handle equal versions
    if [ "$ver1" = "$ver2" ]; then
        case "$op" in
            "="|">="|"<=") return 0 ;;
            *) return 1 ;;
        esac
    fi

    # Normalize versions: split by dots, handle arbitrary components
    # Convert: 2.38.1 -> "2 38 1", 1.2.3.4.5 -> "1 2 3 4 5"
    v1_parts=$(printf '%s' "$ver1" | tr '.' ' ' | tr '-' ' ')
    v2_parts=$(printf '%s' "$ver2" | tr '.' ' ' | tr '-' ' ')

    # Compare component by component
    v1_remaining="$v1_parts"
    v2_remaining="$v2_parts"

    while true; do
        # Extract first component from each
        v1_part=$(printf '%s' "$v1_remaining" | awk '{print $1}')
        v2_part=$(printf '%s' "$v2_remaining" | awk '{print $1}')

        # If both exhausted, versions are equal
        [ -z "$v1_part" ] && [ -z "$v2_part" ] && {
            case "$op" in
                "="|">="|"<=") return 0 ;;
                *) return 1 ;;
            esac
        }

        # Treat missing parts as 0
        [ -z "$v1_part" ] && v1_part=0
        [ -z "$v2_part" ] && v2_part=0

        # Extract numeric prefix (handles "1rc2" -> "1")
        v1_num=$(printf '%s' "$v1_part" | sed 's/[^0-9].*//')
        v2_num=$(printf '%s' "$v2_part" | sed 's/[^0-9].*//')

        [ -z "$v1_num" ] && v1_num=0
        [ -z "$v2_num" ] && v2_num=0

        # Compare this component
        if [ "$v1_num" -gt "$v2_num" ]; then
            case "$op" in
                ">"|">=") return 0 ;;
                *) return 1 ;;
            esac
        elif [ "$v1_num" -lt "$v2_num" ]; then
            case "$op" in
                "<"|"<=") return 0 ;;
                *) return 1 ;;
            esac
        fi

        # This component equal, continue to next
        v1_remaining=$(printf '%s' "$v1_remaining" | cut -d' ' -f2-)
        v2_remaining=$(printf '%s' "$v2_remaining" | cut -d' ' -f2-)

        # Prevent infinite loop
        [ "$v1_remaining" = "$v1_parts" ] && [ "$v2_remaining" = "$v2_parts" ] && break
        v1_parts="$v1_remaining"
        v2_parts="$v2_remaining"
    done

    # Fallback: equal
    case "$op" in
        "="|">="|"<=") return 0 ;;
        *) return 1 ;;
    esac
}

check_versioned_deps() {
    pkg="$1"

    deps_file=""
    pkg_path=$(resolve_installed_path "$pkg") 2>/dev/null || pkg_path="$pkg"
    deps_file="$DB_DIR/$pkg_path/depends"

    if [ ! -f "$deps_file" ]; then
        rpath=$(recipe_path "$pkg") 2>/dev/null || rpath=""
        [ -n "$rpath" ] && deps_file="$rpath/depends"
    fi

    [ ! -f "$deps_file" ] && return 0

    info "Checking versioned dependencies for $pkg..."

    while IFS= read -r depline; do
        depline=$(printf '%s' "$depline" | sed 's/^[[:space:]]*//; s/[[:space:]]*$//')
        [ -z "$depline" ] && continue
        case "$depline" in \#*) continue ;; esac

        # Parse: package_name [>=/<=/>/<] version
        dep_pkg=$(printf '%s' "$depline" | awk '{print $1}')
        dep_op=$(printf '%s' "$depline" | awk '{print $2}')
        dep_ver=$(printf '%s' "$depline" | awk '{print $3}')

        # No version constraint
        if [ -z "$dep_op" ] || [ -z "$dep_ver" ]; then
            continue
        fi

        # Check if installed
        if ! is_pkg_installed "$dep_pkg"; then
            warn "  ✗ $dep_pkg $dep_op $dep_ver (NOT INSTALLED)"
            return 1
        fi

        # Get version
        installed_ver=$(get_installed_ver "$dep_pkg")
        [ "$installed_ver" = "none" ] && installed_ver="0.0.0"

        # Compare
        if version_compare "$installed_ver" "$dep_op" "$dep_ver"; then
            info "  ✓ $dep_pkg $dep_op $dep_ver (installed: $installed_ver)"
        else
            warn "  ✗ $dep_pkg $dep_op $dep_ver (installed: $installed_ver) - VERSION MISMATCH"
            return 1
        fi
    done < "$deps_file"

    return 0
}

# === DETECTION FUNCTION ===
# Returns 0 if .stars file, 1 if directory recipe, 2 if not found
detect_recipe_format() {
    pkg="$1"

    # Check for .stars file first (faster)
    if [ -f "$RECIPES_DIR/$pkg.stars" ]; then
        printf 'stars\n'
        return 0
    fi

    # Check for category/pkg.stars
    stars_path=$(find "$RECIPES_DIR" -type f -name "$pkg.stars" -maxdepth 2 2>/dev/null | head -n1)
    if [ -n "$stars_path" ]; then
        printf 'stars\n'
        return 0
    fi

    # Check for directory-based recipe
    if [ -d "$RECIPES_DIR/$pkg" ]; then
        printf 'directory\n'
        return 0
    fi

    # Check in subdirectories
    dir_path=$(find "$RECIPES_DIR" -type d -name "$pkg" -maxdepth 2 2>/dev/null | head -n1)
    if [ -n "$dir_path" ]; then
        printf 'directory\n'
        return 0
    fi

    # Not found
    return 1
}

astral_version() {
cat <<EOF
┌──────────────────────┐
│ Astral: $version │
└──────────────────────┘
EOF
    exit 0
}

usage() {
    cat <<USAGE
┌──────────────────────┐
│ Astral: $version │
└──────────────────────┘
┌───────────────────────────────────┐
│ Astral File is in $SCRIPT_PATH │
└───────────────────────────────────┘
┌────────────────────────────────────────────────┐
│ Usage: astral [global_opts] <command> [pkg...] │
└────────────────────────────────────────────────┘

Global Options:
  --dir <DIR>             Installation root (default: /)
  -f, --force             Force operation (bypass conflicts)
  -n, --dry-run           Preview without making changes
  -v, --verbose           Enable verbose output

Package Management:
  -S, --Sync <pkg>        Install/upgrade from AOHARU
  -SA, --Sync-Asura <pkg> Install from ASURA (community overlay)
  -C, --Compile <pkg>     Build from local recipe
  -R, --Remove <pkg>      Remove package
  -r, --RemoveDep <pkg>   Remove package + orphaned deps
  --autoremove            Remove all orphaned packages
  -Re, --resume <pkg>     Resume interrupted build

Query & Information:
  -s, --search <pkg>      Search for packages
  -I, --info <pkg>        Show package details
  -D, --Deps <pkg>        Show dependency tree
  -Dc, --DepCheck         Check for broken dependencies
  -p, --preview <pkg>     Preview install
  -w, --why <pkg>         Show why package is installed
  -W, --world             List explicitly installed packages
  -ll, --List-Installed   List all installed packages
  --host-check <pkg>      Test if package is on host
  --host-deps             Show all host dependencies

  Store Operations:
  --enable-store          Enable store-based package management
  --disable-store         Disable store mode (use legacy)
  -si, --store-info       Show store information
  --rollback              Revert to previous generation
  -lg, --list-generations List all system generations
  --switch-generation N   Switch to generation N
  --gc [--dry-run]        Garbage collect unreferenced packages

System Operations:
  -UA, --Upgrade-All      Upgrade all packages
  -u, --Update [repo]     Update repository index
  -Cc, --Clean-Cache      Clean uninstalled recipes
  -RI, --rebuild-index    Rebuild file ownership index

Advanced Features:
  --ccache-stats          Show ccache statistics
  --ccache-clear          Clear ccache
  --list-virtuals         Show virtual package providers
  --mask <pkg [op ver]>   Mask package version
  --unmask <pkg>          Unmask package
  --config                Show configuration
  -SE, --show-env         Show build environment

Maintenance:
  -U, --self-update [br]  Update Astral itself
  -V, --Version           Show version

┌───────────────────────────────────────┐
│ Astral is maintained by One Masochist │
└───────────────────────────────────────┘
USAGE
}

# --- CORE UTILITY FUNCTIONS ---

is_pkg_installed() {
    pkg="$1"
    [ -d "$DB_DIR/$pkg" ] || [ -n "$(find "$DB_DIR" -type d -name "$pkg" -maxdepth 2 2>/dev/null)" ]
}

resolve_installed_path() {
    requested_pkg="$1"

    if [ -d "$DB_DIR/$requested_pkg" ]; then
        printf '%s\n' "$requested_pkg"
        return 0
    fi

    found_path=$(find "$DB_DIR" -type d -name "$requested_pkg" -maxdepth 2 2>/dev/null | head -n 1 || true)
    if [ -n "$found_path" ]; then
        printf '%s\n' "$(printf '%s' "$found_path" | sed "s|^${DB_DIR}/||")"
        return 0
    fi

    return 1
}

# helper: find recipe path - search subdirectories
recipe_path() {
    _pkg="$1"

    # Priority 1: Check for .stars file in root
    if [ -f "$RECIPES_DIR/$_pkg.stars" ]; then
        printf '%s\n' "$RECIPES_DIR/$_pkg.stars"
        return 0
    fi

    # Priority 2: Check for .stars in subdirectories (category/pkg.stars)
    stars_found=$(find "$RECIPES_DIR" -type f -name "$_pkg.stars" -maxdepth 2 2>/dev/null | head -n1)
    if [ -n "$stars_found" ]; then
        printf '%s\n' "$stars_found"
        return 0
    fi

    # Priority 3: Directory-based recipes (existing behavior)
    if [ -d "$RECIPES_DIR/$_pkg" ]; then
        printf '%s\n' "$RECIPES_DIR/$_pkg"
        return 0
    fi

    found_path=$(find "$RECIPES_DIR" -type d -name "$_pkg" -maxdepth 2 2>/dev/null | head -n 1 || true)
    if [ -n "$found_path" ] && [ -d "$found_path" ]; then
        printf '%s\n' "$found_path"
        return 0
    fi

    return 1
}

# === STARS FILE PARSER ===
# Extract sections from .stars file
parse_stars_section() {
    stars_file="$1"
    section_name="$2"  # e.g., "BUILD", "PACKAGE", "SOURCES"

    awk -v section="$section_name" '
        /^@[A-Z_]+$/ {
            in_section = 0
            if ($0 == "@" section) in_section = 1
            next
        }
        in_section { print }
    ' "$stars_file"
}

# Extract metadata (KEY=VALUE lines before first @SECTION)
parse_stars_metadata() {
    stars_file="$1"
    awk '/^@[A-Z_]+$/ { exit } /^[A-Z_]+=/ { print }' "$stars_file"
}


# Get installed version (returns "none" if not installed)
get_installed_ver() {
    requested_pkg="$1"
    pkg_path=$(resolve_installed_path "$requested_pkg") || { printf 'none\n'; return 0; }

    if [ -f "$DB_DIR/$pkg_path/version" ]; then
        cat "$DB_DIR/$pkg_path/version"
    else
        printf 'none\n'
    fi
}

create_meta() {
    pkg="$1"; ver="$2"; arch="$3"; dest="$4"
    cat > "$dest/.astral-meta" <<M
name=$pkg
version=$ver
arch=$arch
M
}

atomic_install() {
    pkg="$1"
    pkgdir_src="$2"
    recipe_ver="$3"
    rpath="$4"              # This could be a temp expanded path!
    new_files="$5"

    # Create staging directory
    staging_root="$TMPDIR/astral-staging-$$"
    mkdir -p "$staging_root" || err "[$pkg] Failed to create staging directory"

    info "[$pkg] Installing to staging area..."

    # Install to staging first
    tar -C "$pkgdir_src" -cf - . | tar -C "$staging_root" -xf - || {
        rm -rf "$staging_root"
        err "[$pkg] Failed to extract to staging area"
    }

    # FIX: Calculate db_path correctly (handle both directory and .stars expansion)
    db_path=""
    if [ -f "$rpath/.astral_original_recipe" ]; then
        # This was expanded from .stars, read the original path
        original_rpath=$(cat "$rpath/.astral_original_recipe")
        db_path=$(printf '%s' "$original_rpath" | sed "s|^${RECIPES_DIR}/||; s|\.stars$||")
    else
        # Regular directory recipe
        db_path=$(printf '%s' "$rpath" | sed "s|^${RECIPES_DIR}/||")
    fi

    # Prepare DB entry (but don't commit yet)
    db_target="$DB_DIR/$db_path"
    db_staging="$TMPDIR/astral-db-staging-$$"
    mkdir -p "$db_staging"

    printf '%s\n' "$recipe_ver" > "$db_staging/version"
    printf '%s\n' "$new_files" > "$db_staging/files"
    buildtmp_parent="$(dirname "$pkgdir_src")"
    [ -f "$buildtmp_parent/depends" ] && cp "$buildtmp_parent/depends" "$db_staging/depends"
    [ -f "$buildtmp_parent/bdepends" ] && cp "$buildtmp_parent/bdepends" "$db_staging/bdepends"
    [ -f "$buildtmp_parent/rdepends" ] && cp "$buildtmp_parent/rdepends" "$db_staging/rdepends"

    # ATOMIC COMMIT: Move files and DB together
    info "[$pkg] Committing installation atomically..."

    # Move files from staging to real root (atomically)
    if ! ( cd "$staging_root" && tar cf - . ) | ( cd "$INSTALL_ROOT" && tar xf - ); then
        rm -rf "$staging_root" "$db_staging"
        err "[$pkg] Failed to install files atomically"
    fi

    # Finally, commit DB (last step - if this fails files are there but untracked)
    mkdir -p "$db_target"
    mv "$db_staging/version" "$db_target/version" || {
        warn "[$pkg] DB commit failed - package installed but not tracked!"
        rm -rf "$staging_root" "$db_staging"
        err "[$pkg] Database commit failed"
    }
    mv "$db_staging/files" "$db_target/files"
    [ -f "$db_staging/depends" ] && mv "$db_staging/depends" "$db_target/depends"
    [ -f "$db_staging/bdepends" ] && mv "$db_staging/bdepends" "$db_target/bdepends"
    [ -f "$db_staging/rdepends" ] && mv "$db_staging/rdepends" "$db_target/rdepends"
    update_files_index_for_pkg "$db_path"

    # Cleanup
    rm -rf "$staging_root" "$db_staging"

    info "[$pkg] ✓ Atomic installation complete"
}

# Extracts dependency names from the depends file, filtering comments and empty lines.
get_pkg_deps() {
    pkg="$1"

    # Legacy depends file (both build and runtime)
    legacy_deps=$(get_legacy_deps "$pkg")

    # New split format
    build_deps=$(get_build_deps "$pkg")
    runtime_deps=$(get_runtime_deps "$pkg")

    # Combine and deduplicate
    printf '%s\n%s\n%s\n' "$legacy_deps" "$build_deps" "$runtime_deps" | \
        grep -v '^[[:space:]]*$' | sort -u
}

get_legacy_deps() {
    pkg="$1"
    depfile=""

    pkg_path=$(resolve_installed_path "$pkg") 2>/dev/null || pkg_path="$pkg"
    depfile="$DB_DIR/$pkg_path/depends"

    if [ ! -f "$depfile" ]; then
        rpath=$(recipe_path "$pkg") 2>/dev/null || rpath=""
        [ -n "$rpath" ] && depfile="$rpath/depends"
    fi

    [ -f "$depfile" ] || return 0
    grep -v '^[[:space:]]*#' "$depfile" | grep -E -v '^[[:space:]]*$' | awk '{print $1}' || true
}

get_build_deps() {
    pkg="$1"
    depfile=""

    pkg_path=$(resolve_installed_path "$pkg") 2>/dev/null || pkg_path="$pkg"
    depfile="$DB_DIR/$pkg_path/bdepends"

    if [ ! -f "$depfile" ]; then
        rpath=$(recipe_path "$pkg") 2>/dev/null || rpath=""
        [ -n "$rpath" ] && depfile="$rpath/bdepends"
    fi

    [ -f "$depfile" ] || return 0
    grep -v '^[[:space:]]*#' "$depfile" | grep -E -v '^[[:space:]]*$' | awk '{print $1}' || true
}

# Get runtime dependencies (RDEPEND)
get_runtime_deps() {
    pkg="$1"
    depfile=""

    pkg_path=$(resolve_installed_path "$pkg") 2>/dev/null || pkg_path="$pkg"
    depfile="$DB_DIR/$pkg_path/rdepends"

    if [ ! -f "$depfile" ]; then
        rpath=$(recipe_path "$pkg") 2>/dev/null || rpath=""
        [ -n "$rpath" ] && depfile="$rpath/rdepends"
    fi

    [ -f "$depfile" ] || return 0
    grep -v '^[[:space:]]*#' "$depfile" | grep -E -v '^[[:space:]]*$' | awk '{print $1}' || true
}

# Checks if a package (by DB relative path) is required by any other installed package.
is_pkg_required() {
    target_pkg_path="$1"
    target_pkg=$(basename "$target_pkg_path")

    for other_pkg_dir in "$DB_DIR"/*/* "$DB_DIR"/*; do
        [ -d "$other_pkg_dir" ] || continue
        other_pkg_path=$(printf '%s' "$other_pkg_dir" | sed "s|^${DB_DIR}/||")
        [ "$other_pkg_path" = "$target_pkg_path" ] && continue

        other_deps=$(get_pkg_deps "$other_pkg_path" 2>/dev/null || true)
        if printf '%s\n' "$other_deps" | grep -qE "^${target_pkg_path}$|^${target_pkg}$"; then
            return 0
        fi
    done

    return 1
}

# --- HOST DEPENDENCY DETECTION ---
# Returns 0 if dependency is satisfied by host (binary in PATH or shared lib)
check_host_dependency() {
    dep="$1"

    # Verbose debugging (set ASTRAL_DEBUG=1 to enable)
    debug() {
        [ "${ASTRAL_DEBUG:-0}" = "1" ] && warn "[HOST-CHECK] $*"
    }

    debug "Checking host for: $dep"

    # Priority 1: Check config override first (fastest)
    case " $HOST_PROVIDED " in
        *" $dep "*)
            debug "  ✓ Found in HOST_PROVIDED config"
            return 0
            ;;
    esac

    # Priority 2: Check pkg-config (most reliable for libraries)
    if command -v pkg-config >/dev/null 2>&1; then
        if pkg-config --exists "$dep" 2>/dev/null; then
            debug "  ✓ Found via pkg-config"
            return 0
        fi
        debug "  ✗ Not found in pkg-config"
    fi

    # Priority 3: Check if it's a binary in PATH
    if command -v "$dep" >/dev/null 2>&1; then
        # Verify the binary actually exists and is executable
        dep_path=$(command -v "$dep")
        if [ -x "$dep_path" ]; then
            return 0
        fi
    fi
    debug "  ✗ Not in PATH"

    # Priority 4: Library checking (complex cases)
    case "$dep" in
        lib*.so*|*.so*)
            debug "  → Checking as shared library"
            if check_shared_library "$dep"; then
                debug "  ✓ Found as shared library"
                return 0
            fi
            debug "  ✗ Not found as shared library"
            ;;
        *)
            # Try with lib prefix
            debug "  → Trying with lib prefix"
            if check_shared_library "lib${dep}"; then
                debug "  ✓ Found as lib${dep}"
                return 0
            fi
            debug "  ✗ Not found as lib${dep}"
            ;;
    esac

    debug "  ✗ NOT FOUND on host"
    return 1
}
check_shared_library() {
    lib_pattern="$1"

    # Method 1: ldconfig cache (fastest, but might be stale)
    if command -v ldconfig >/dev/null 2>&1; then
        # ONLY match actual .so files, not .a or other junk
        if ldconfig -p 2>/dev/null | grep -qE "${lib_pattern}\.so(\.[0-9]+)*[[:space:]]"; then
            return 0
        fi
    fi

    # Method 2: Direct filesystem search - ONLY .so files
    for libdir in /lib /usr/lib /lib64 /usr/lib64 /usr/local/lib /usr/local/lib64; do
        [ -d "$libdir" ] || continue

        # STRICT: Only match .so or .so.X.Y.Z files
        if find "$libdir" -maxdepth 1 \( -name "${lib_pattern}.so" -o -name "${lib_pattern}.so.*" \) 2>/dev/null | grep -q .; then
            return 0
        fi
    done

    return 1
}

show_host_deps() {
    info "=== Host Dependency Analysis ==="

    info ""
    info "Compilers:"
    for tool in gcc g++ cc clang clang++ tcc; do
        if command -v "$tool" >/dev/null 2>&1; then
            version=$("$tool" --version 2>/dev/null | head -n1)
            info "  ✓ $tool: $version"
        else
            info "  ✗ $tool: not found"
        fi
    done

    info ""
    info "Build Tools:"
    for tool in make cmake meson ninja automake autoconf libtool pkg-config; do
        if command -v "$tool" >/dev/null 2>&1; then
            info "  ✓ $tool"
        else
            info "  ✗ $tool"
        fi
    done

    info ""
    info "Common Libraries (via pkg-config):"
    if command -v pkg-config >/dev/null 2>&1; then
        for lib in zlib openssl ncurses readline; do
            if pkg-config --exists "$lib" 2>/dev/null; then
                version=$(pkg-config --modversion "$lib" 2>/dev/null)
                info "  ✓ $lib: $version"
            else
                info "  ✗ $lib: not found"
            fi
        done
    else
        warn "  pkg-config not available"
    fi

    info ""
    info "Library Paths:"
    for libdir in /lib /usr/lib /lib64 /usr/lib64; do
        if [ -d "$libdir" ]; then
            count=$(find "$libdir" -name "*.so*" 2>/dev/null | wc -l)
            info "  $libdir: $count libraries"
        fi
    done

    info ""
    info "ldconfig cache:"
    if command -v ldconfig >/dev/null 2>&1; then
        cache_count=$(ldconfig -p 2>/dev/null | wc -l)
        info "  Cached libraries: $cache_count"
    else
        warn "  ldconfig not available"
    fi
}

test_host_dependency() {
    test_pkg="$1"

    info "=== Testing Host Dependency Check ==="
    info "Package: $test_pkg"
    info ""

    # Enable debug mode
    ASTRAL_DEBUG=1
    export ASTRAL_DEBUG

    if check_host_dependency "$test_pkg"; then
        info ""
        info "✓ RESULT: $test_pkg IS available on host"
        return 0
    else
        info ""
        info "✗ RESULT: $test_pkg NOT available on host"
        return 1
    fi
}

# === STARS RECIPE EXPANSION ===
# Expand .stars file to temporary directory structure
expand_stars_recipe() {
    stars_file="$1"
    temp_dir="$2"

    mkdir -p "$temp_dir"

    info "  → Expanding .stars recipe..."

    # Store original recipe path for later reference
    printf '%s\n' "$stars_file" > "$temp_dir/.astral_original_recipe"

    # Detect format version by checking first 20 lines
    if head -n 20 "$stars_file" | grep -qE '^\$PKG\.'; then
        info "  → Detected v2 format (\$PKG.* syntax)"
        parse_stars_v2 "$stars_file" "$temp_dir"
    else
        info "  → Detected v1 format (@SECTION syntax)"
        parse_stars_v1 "$stars_file" "$temp_dir"
    fi
}

# === V2 yeah

parse_stars_v2() {
    stars_file="$1"
    temp_dir="$2"

    # State machine variables
    current_section=""
    current_subsection=""
    in_block=0
    block_content=""
    condition=""
    arch=$(uname -m)
    skip_section=0

    while IFS= read -r line || [ -n "$line" ]; do
        # Remove leading/trailing whitespace
        line=$(printf '%s' "$line" | sed 's/^[[:space:]]*//; s/[[:space:]]*$//')

        # Skip empty lines outside blocks
        if [ $in_block -eq 0 ]; then
            [ -z "$line" ] && continue
            case "$line" in \#*) continue ;; esac
        fi

        # === SECTION DETECTION ===
        case "$line" in
            \$PKG.Metadata:*|\$PKG.Metadate:*)
                current_section="metadata"
                in_block=1
                block_content=""
                skip_section=0
                info "    → Metadata"
                continue
                ;;

            \$PKG.Build*)
                current_section="build"
                skip_section=0

                # Extract and evaluate condition
                if printf '%s' "$line" | grep -qE '\[IF '; then
                    condition=$(printf '%s' "$line" | sed -n 's/.*\[IF \([^]]*\)\].*/\1/p')

                    cond_var=$(printf '%s' "$condition" | cut -d'=' -f1 | tr -d ' ')
                    cond_val=$(printf '%s' "$condition" | cut -d'=' -f2 | tr -d ' ')

                    case "$cond_var" in
                        arch)
                            if [ "$arch" != "$cond_val" ]; then
                                skip_section=1
                                info "    ⊘ Build (skipped: arch != $cond_val)"
                            else
                                info "    → Build (arch=$cond_val)"
                            fi
                            ;;
                    esac
                else
                    info "    → Build"
                fi

                in_block=1
                block_content=""
                continue
                ;;

            \$PKG.Package*)
                current_section="package"
                skip_section=0
                in_block=1
                block_content=""
                info "    → Package"
                continue
                ;;

            \$PKG.Depend*)
                # Check if it's a subsection
                if printf '%s' "$line" | grep -q '\$PKG.Depend.BDepends'; then
                    current_section="depend"
                    current_subsection="bdepends"
                    skip_section=0
                    in_block=1
                    block_content=""
                    info "      → BDepends"
                elif printf '%s' "$line" | grep -q '\$PKG.Depend.RDepends'; then
                    current_section="depend"
                    current_subsection="rdepends"
                    skip_section=0
                    in_block=1
                    block_content=""
                    info "      → RDepends"
                else
                    current_section="depend"
                    current_subsection=""
                    skip_section=0
                    in_block=1
                    block_content=""
                    info "    → Depend"
                fi
                continue
                ;;

            \$PKG.Sources*)
                current_section="sources"
                skip_section=0
                in_block=1
                block_content=""
                info "    → Sources"
                continue
                ;;

            \$PKG.Checksums*)
                current_section="checksums"
                skip_section=0
                in_block=1
                block_content=""
                info "    → Checksums"
                continue
                ;;

            \$PKG.PostInstall*)
                current_section="post_install"
                skip_section=0
                in_block=1
                block_content=""
                info "    → PostInstall"
                continue
                ;;

            \$PKG.PostRemove*)
                current_section="post_remove"
                skip_section=0
                in_block=1
                block_content=""
                info "    → PostRemove"
                continue
                ;;
        esac

        # === BLOCK CLOSING ===
        if [ "$line" = "};" ] || [ "$line" = "}" ]; then
            in_block=0

            # Process block if not skipped
            if [ $skip_section -eq 0 ] && [ -n "$current_section" ]; then
                case "$current_section" in
                    metadata)
                        parse_metadata_block_v2 "$block_content" "$temp_dir"
                        ;;
                    build|package|post_install|post_remove)
                        write_script_section_v2 "$current_section" "$block_content" "$temp_dir"
                        ;;
                    depend)
                        if [ -n "$current_subsection" ]; then
                            write_deps_section_v2 "$current_subsection" "$block_content" "$temp_dir"
                        fi
                        ;;
                    sources)
                        write_sources_section_v2 "$block_content" "$temp_dir"
                        ;;
                    checksums)
                        write_checksums_section_v2 "$block_content" "$temp_dir"
                        ;;
                esac
            fi

            block_content=""
            current_section=""
            current_subsection=""
            skip_section=0
            continue
        fi

        # === ACCUMULATE CONTENT ===
        if [ $in_block -eq 1 ]; then
            # Skip opening brace
            case "$line" in "{") continue ;; esac

            if [ -z "$block_content" ]; then
                block_content="$line"
            else
                block_content="$block_content
$line"
            fi
        fi

    done < "$stars_file"
}

# Helper: Parse metadata block
parse_metadata_block_v2() {
    content="$1"
    temp_dir="$2"

    printf '%s\n' "$content" | while IFS= read -r line; do
        [ -z "$line" ] && continue

        # Parse KEY = "VALUE"
        key=$(printf '%s' "$line" | cut -d'=' -f1 | tr -d ' ' | tr 'A-Z' 'a-z')
        value=$(printf '%s' "$line" | cut -d'=' -f2- | sed 's/^[[:space:]]*"//; s/"[[:space:]]*$//')

        case "$key" in
            version)
                printf '%s\n' "$value" > "$temp_dir/version"
                ;;
            description)
                printf '%s\n' "$value" > "$temp_dir/info"
                ;;
            homepage)
                printf '%s\n' "$value" >> "$temp_dir/info"
                ;;
            category)
                # Store category for later use if needed
                printf '%s\n' "$value" > "$temp_dir/.category"
                ;;
        esac
    done
}

# Helper: Write script sections
write_script_section_v2() {
    section="$1"
    content="$2"
    temp_dir="$3"

    printf '#!/bin/sh\n%s\n' "$content" > "$temp_dir/$section"
    chmod +x "$temp_dir/$section"
}

# Helper: Write dependency sections
write_deps_section_v2() {
    subsection="$1"
    content="$2"
    temp_dir="$3"

    printf '%s\n' "$content" | while IFS= read -r line; do
        [ -z "$line" ] && continue
        printf '%s\n' "$line"
    done > "$temp_dir/$subsection"
}

# Helper: Write sources
write_sources_section_v2() {
    content="$1"
    temp_dir="$2"

    printf '%s\n' "$content" | while IFS= read -r line; do
        [ -z "$line" ] && continue

        # Parse: urls = "..."
        if printf '%s' "$line" | grep -q '^urls[[:space:]]*='; then
            url=$(printf '%s' "$line" | cut -d'=' -f2- | sed 's/^[[:space:]]*"//; s/"[[:space:]]*$//')
            printf '%s\n' "$url"
        fi
    done > "$temp_dir/sources"
}

# Helper: Write checksums
write_checksums_section_v2() {
    content="$1"
    temp_dir="$2"

    printf '%s\n' "$content" > "$temp_dir/checksums"
}

# v1 Parser (OLD FORMAT - backward compatibility)
parse_stars_v1() {
    stars_file="$1"
    temp_dir="$2"

    # Extract metadata
    awk '/^@[A-Z_]+$/ { exit } /^[A-Z_]+=/ { print }' "$stars_file" | \
    while IFS='=' read -r key value; do
        case "$key" in
            VERSION)
                printf '%s\n' "$value" > "$temp_dir/version"
                info "    ✓ VERSION: $value"
                ;;
            DESCRIPTION)
                printf '%s\n' "$value" > "$temp_dir/info"
                ;;
            HOMEPAGE)
                printf '%s\n' "$value" >> "$temp_dir/info"
                ;;
        esac
    done

    # Extract sections
    for section in BUILD PACKAGE POST_INSTALL POST_REMOVE DEPENDS BDEPENDS RDEPENDS SOURCES CHECKSUMS; do
        content=$(awk -v section="$section" '
            /^@[A-Z_]+$/ {
                in_section = 0
                if ($0 == "@" section) in_section = 1
                next
            }
            in_section { print }
        ' "$stars_file")

        if [ -n "$content" ]; then
            case "$section" in
                BUILD|PACKAGE|POST_INSTALL|POST_REMOVE)
                    lower=$(printf '%s' "$section" | tr 'A-Z' 'a-z')
                    printf '#!/bin/sh\n%s\n' "$content" > "$temp_dir/$lower"
                    chmod +x "$temp_dir/$lower"
                    info "    ✓ $section"
                    ;;
                *)
                    lower=$(printf '%s' "$section" | tr 'A-Z' 'a-z')
                    printf '%s\n' "$content" > "$temp_dir/$lower"
                    info "    ✓ $section"
                    ;;
            esac
        fi
    done
}

# --- NETWORKING / RECIPE FUNCTIONS ---
fetch_remote_recipe() {
    _pkg="$1"
    _force_repo="${2:-$REPO_CONTEXT}"

    info "Attempting to fetch or refresh recipe for '$_pkg' from $_force_repo..."

    # Check if recipe already exists locally
    existing_rpath=$(recipe_path "$_pkg") 2>/dev/null || existing_rpath=""

    if [ -n "$existing_rpath" ]; then
        category_pkg=$(printf '%s' "$existing_rpath" | sed "s|^${RECIPES_DIR}/||")
        local_dir="$RECIPES_DIR/$category_pkg"
    else
        # Determine which index to search based on repo context
        case "$_force_repo" in
            asura)
                search_index="$INDEX_FILE_ASURA"
                info "  → Searching ASURA index..."
                ;;
            aoharu|*)
                search_index="$INDEX_FILE_AOHARU"
                info "  → Searching AOHARU index..."
                ;;
        esac

        # Recipe doesn't exist - check if pkg has category already
        case "$_pkg" in
            */*)
                category_pkg="$_pkg"
                ;;
            *)
                category=""
                if [ -f "$search_index" ]; then
                    category=$(grep "^${_pkg}[[:space:]]" "$search_index" | awk '{print $3}' | head -n1)
                fi

                if [ -z "$category" ] && [ "$_force_repo" = "asura" ] && [ -f "$INDEX_FILE_AOHARU" ]; then
                    category=$(grep "^${_pkg}[[:space:]]" "$INDEX_FILE_AOHARU" | awk '{print $3}' | head -n1)
                fi

                if [ -z "$category" ] && [ "$_force_repo" = "aoharu" ] && [ -f "$INDEX_FILE_ASURA" ]; then
                    category=$(grep "^${_pkg}[[:space:]]" "$INDEX_FILE_ASURA" | awk '{print $3}' | head -n1)
                fi

                if [ -n "$category" ]; then
                    category_pkg="${category}/${_pkg}"
                else
                    category_pkg="$_pkg"
                fi
                ;;
        esac

        local_dir="$RECIPES_DIR/$category_pkg"
    fi

    mkdir -p "$local_dir"

    # Build remote URL based on repo context
    case "$_force_repo" in
        asura)
            remote_base="${USER_RECIPE_RAW_URL%/}/recipes/${category_pkg}"
            ;;
        aoharu|*)
            remote_base="${RECIPE_RAW_URL%/}/recipes/${category_pkg}"
            ;;
    esac

    # Try downloading .stars file (two possible locations)
    stars_url_flat="${remote_base}.stars"
    stars_url_nested="${remote_base}/$(basename "$category_pkg").stars"
    stars_dest="${local_dir}.stars"

    # Try flat structure first (category/package.stars)
    if curl -f#SL "$stars_url_flat" -o "$stars_dest" 2>/dev/null; then
        info "Downloaded .stars recipe (flat): $stars_dest"
        mkdir -p "$local_dir"
        expand_stars_recipe "$stars_dest" "$local_dir"
        return 0
    fi

    # Try nested structure (category/package/package.stars)
    if curl -f#SL "$stars_url_nested" -o "$stars_dest" 2>/dev/null; then
        info "Downloaded .stars recipe (nested): $stars_dest"
        mkdir -p "$local_dir"
        expand_stars_recipe "$stars_dest" "$local_dir"
        return 0
    fi

    # Fallback to directory-based recipe if .stars not found
    info "  → .stars not found, trying directory-based recipe..."

    required_files="version build"
    optional_files="depends bdepends rdepends package post_install post_remove checksums conflicts info sources"

    # Download directory-based files
    for file in $required_files $optional_files; do
        url="$remote_base/$file"
        dest="$local_dir/$file"

        if curl -f#SL "$url" -o "$dest" 2>/dev/null; then
            :
        else
            if printf '%s' "$required_files" | grep -qw "$file"; then
                err "Failed to fetch mandatory file '$file' for package '$_pkg' from $url ($_force_repo repo)"
            fi
            rm -f "$dest"
        fi
    done

    # Make scripts executable
    chmod +x "$local_dir/build" 2>/dev/null || true
    chmod +x "$local_dir/package" 2>/dev/null || true
    chmod +x "$local_dir/post_install" 2>/dev/null || true
    chmod +x "$local_dir/post_remove" 2>/dev/null || true

    info "Recipe for '$_pkg' fetched from $_force_repo at $local_dir."
}

fetch_remote_recipe_stars() {
    _pkg="$1"

    info "Attempting to fetch .stars recipe for '$_pkg' from remote..."

    # Determine category
    category=""
    if [ -f "$INDEX_FILE_AOHARU" ]; then
        category=$(grep "^${_pkg}[[:space:]]" "$INDEX_FILE_AOHARU" | awk '{print $3}' | head -n1)
    fi

    # Try to fetch .stars file first
    remote_url="${RECIPE_RAW_URL%/}/recipes/${category:+$category/}${_pkg}.stars"
    local_path="$RECIPES_DIR/${category:+$category/}${_pkg}.stars"

    mkdir -p "$(dirname "$local_path")"

    if curl -f#SL "$remote_url" -o "$local_path" 2>/dev/null; then
        info "Downloaded .stars recipe: $local_path"
        return 0
    fi

    # Fallback to directory-based fetch (existing logic)
    return 1
}

download_sources() {
    rpath="$1"; buildtmp="$2"
    sources_file="$rpath/sources"
    [ -f "$sources_file" ] || return 0

    info "Downloading source archives..."

    filtered_sources=$(grep -v '^[[:space:]]*#' "$sources_file" | grep -E -v '^[[:space:]]*$' || true)

    printf '%s\n' "$filtered_sources" | while IFS= read -r url; do
        url=$(printf '%s' "$url" | tr -d '[:space:]')
        [ -z "$url" ] && continue
        filename=$(basename "$url")
        dest_file="$buildtmp/$filename"

        info "  -> Downloading $filename"
        if ! curl -f#SL "$url" -o "$dest_file"; then
            err "Failed to download source file from $url"
        fi
    done
}

verify_checksums_and_extract() {
    pkg="$1"; rpath="$2"; buildtmp="$3"
    checksums_file="$rpath/checksums"
    [ -f "$checksums_file" ] || { info "No checksums provided for $pkg. Skipping integrity check."; return 0; }

    command -v sha256sum >/dev/null 2>&1 || err "sha256sum command not found. Cannot verify source integrity."

    info "Verifying source integrity using checksums..."

    while IFS= read -r line; do
        line=$(printf '%s' "$line" | sed 's/^[[:space:]]*//; s/[[:space:]]*$//')
        [ -z "$line" ] && continue
        case "$line" in \#*) continue ;; esac

        if printf '%s' "$line" | grep -q ':'; then
            # Format: sha256:hash filename
            expected_hash=$(printf '%s' "$line" | cut -d' ' -f1 | cut -d':' -f2)
            filename=$(printf '%s' "$line" | awk '{print $2}')
        else
            # Format: hash filename
            expected_hash=$(printf '%s' "$line" | awk '{print $1}')
            filename=$(printf '%s' "$line" | awk '{print $2}')
        fi

        [ -n "$expected_hash" ] || err "Checksum file format error for $pkg. Line: '$line'"
        [ -n "$filename" ] || err "Checksum file format error for $pkg. Line: '$line'"

        file_path="$buildtmp/$filename"
        [ -f "$file_path" ] || err "Checksum error: Source file '$filename' not found in build directory. Cannot verify."

        actual_hash=$(sha256sum "$file_path" | awk '{print $1}')
        if [ "$actual_hash" != "$expected_hash" ]; then
            err "Checksum mismatch for $filename! Expected $expected_hash, got $actual_hash. Aborting."
        else
            info "  -> Checksum verified for $filename."
        fi
    done < "$checksums_file"

    info "Checksums verified. Extracting sources..."
    sources_file="$rpath/sources"
    while IFS= read -r url; do
        url=$(printf '%s' "$url" | grep -E -v '^[[:space:]]*#' | grep -E -v '^[[:space:]]*$' || true)
        [ -z "$url" ] && continue
        filename=$(basename "$url")
        dest_file="$buildtmp/$filename"
        info "  -> Extracting $filename"
        case "$filename" in
            *.tar.gz|*.tgz|*.tar.bz2|*.tbz|*.tar.xz|*.txz) tar -xf "$dest_file" -C "$buildtmp" || err "Extract failed for $filename" ;;
            *.zip)
                command -v unzip >/dev/null 2>&1 || err "unzip not found"
                unzip -q "$dest_file" -d "$buildtmp" || err "Unzip failed for $filename" ;;
            *)
                info "  -> Unknown archive type for $filename. Leaving as file."
                ;;
        esac
        rm -f "$dest_file"
    done < "$sources_file"
}

# --- BUILD / SYNC ---
sync_pkg_recursive() {
    _pkg="$1"
    pkg="$_pkg"
    _main_pkg="$pkg"
    FORCE_CMD=${2:-$FORCE_BUILD}
    IS_EXPLICIT=${3:-0}
    _parent_repo="${4:-$REPO_CONTEXT}"

    _pkg=$(sanitize_pkg_name "$_pkg")

    # Check visited (circular dependency)
    case " $VISITED_PACKAGES " in
        *" $_pkg "*)
            err "[$_pkg] CIRCULAR DEPENDENCY DETECTED! Chain: $VISITED_PACKAGES -> $_pkg"
            ;;
    esac

    VISITED_PACKAGES="$VISITED_PACKAGES $_pkg"

    # Set repo context for dependencies
    if [ "$IS_EXPLICIT" -eq 0 ]; then
        REPO_CONTEXT="aoharu"
        info "[$_pkg] Dependency - using AOHARU repository"
    else
        EXPLICIT_PKG_REPO="$REPO_CONTEXT"
    fi

    # === EARLY EXIT CONDITIONS (for dependencies only) ===
    # CHECK BEFORE FETCHING!
    if [ "$IS_EXPLICIT" -eq 0 ]; then
        # Check if already installed
        if is_pkg_installed "$_pkg"; then
            installed_ver=$(get_installed_ver "$_pkg")
            info "Dependency '$_pkg' already installed ($installed_ver). Skipping."
            return 0
        fi

        # Check virtuals
        if check_virtual "$_pkg"; then
            return 0
        fi

        # Check host dependency
        if [ "$FORCE_CMD" -eq 0 ] && check_host_dependency "$_pkg"; then
            info "Dependency '$_pkg' satisfied by host. Skipping build/fetch."
            return 0
        fi
    fi

    # === ONLY REACH HERE IF WE NEED TO ACTUALLY INSTALL ===

    # === FETCH RECIPE IF NEEDED ===
    recipe_exists=0
    if recipe_path "$_pkg" >/dev/null 2>&1; then
        recipe_exists=1
        info "[$_pkg] Using local recipe"
    fi

    if [ "$recipe_exists" -eq 0 ]; then
        if ! fetch_remote_recipe "$_pkg" "$REPO_CONTEXT"; then
            if [ "$IS_EXPLICIT" -eq 0 ] && [ "$REPO_CONTEXT" = "asura" ]; then
                info "[$_pkg] Not found in ASURA, falling back to AOHARU..."
                fetch_remote_recipe "$_pkg" "aoharu" || err "[$_pkg] Recipe not found in any repository"
            else
                err "[$_pkg] Recipe not found in $REPO_CONTEXT repository"
            fi
        fi
    fi

    recipe_dir=$(recipe_path "$_pkg") || err "[$_pkg] Recipe not found after fetch."

    # Expand .stars and get proper paths
    expanded_rpath="$recipe_dir"
    stars_temp=""
    db_path=""

    if [ -f "$recipe_dir" ]; then
        case "$recipe_dir" in
            *.stars)
                stars_temp="$TMPDIR/astral-stars-expand-$_pkg-$$"
                expand_stars_recipe "$recipe_dir" "$stars_temp"
                expanded_rpath="$stars_temp"
                db_path=$(printf '%s' "$recipe_dir" | sed "s|^${RECIPES_DIR}/||; s|\.stars$||")
                ;;
        esac
    else
        db_path=$(printf '%s' "$recipe_dir" | sed "s|^${RECIPES_DIR}/||")
    fi

    # Get version from expanded recipe
    recipe_ver=$(cat "$expanded_rpath/version" 2>/dev/null || printf 'unknown')

    if is_masked "$_pkg" "$recipe_ver"; then
        [ -n "$stars_temp" ] && rm -rf "$stars_temp"
        err "[$_pkg] Package version $recipe_ver is MASKED. Check $MASK_FILE"
    fi

    # === RESOLVE DEPENDENCIES RECURSIVELY ===
    info "Checking dependencies for $_pkg (repo: $REPO_CONTEXT)..."

    _main_pkg="$_pkg"

    deps_tmp=$(mktemp "$TMPDIR/astral-deps.XXXXXX") || err "mktemp failed for dependency resolution"

    # Get deps from expanded recipe if available
    if [ -f "$expanded_rpath/depends" ] || [ -f "$expanded_rpath/bdepends" ] || [ -f "$expanded_rpath/rdepends" ]; then
        # Temporarily create symlink for get_pkg_deps to find
        temp_recipe_link="$RECIPES_DIR/.__temp_$_main_pkg"
        ln -sf "$expanded_rpath" "$temp_recipe_link" 2>/dev/null || true
        get_pkg_deps "$_main_pkg" > "$deps_tmp" 2>/dev/null || touch "$deps_tmp"
        rm -f "$temp_recipe_link"
    else
        get_pkg_deps "$_main_pkg" > "$deps_tmp" 2>/dev/null || touch "$deps_tmp"
    fi

info "DEBUG: Dependencies found for $_main_pkg:"
cat "$deps_tmp" >&2
info "DEBUG: End of dependencies"

    while IFS= read -r dep_pkg; do
        dep_pkg=$(printf '%s' "$dep_pkg" | tr -d '[:space:]')
        [ -z "$dep_pkg" ] && continue

info "DEBUG: About to process dependency: $dep_pkg for main package: $_main_pkg"

        case " $VISITED_PACKAGES " in
            *" $dep_pkg "*)
                rm -f "$deps_tmp"
                [ -n "$stars_temp" ] && rm -rf "$stars_temp"
                err "[$_main_pkg] Would create circular dependency with: $dep_pkg"
                ;;
        esac

        # Recursively install dependency (IS_EXPLICIT=0 means dependency)
        sync_pkg_recursive "$dep_pkg" "$FORCE_CMD" 0 "$REPO_CONTEXT" || {
            rm -f "$deps_tmp"
            [ -n "$stars_temp" ] && rm -rf "$stars_temp"
            err "[$_main_pkg] Failed to install dependency: $dep_pkg"
        }
    done < "$deps_tmp"
    rm -f "$deps_tmp"
    info "DEBUG: Finished processing deps, restoring pkg=$_main_pkg"
pkg="$_main_pkg"

    # === CHECK IF MAIN PACKAGE ALREADY INSTALLED ===
    installed_ver=$(get_installed_ver "$pkg")
    if [ "$installed_ver" = "$recipe_ver" ] && [ "$FORCE_CMD" -eq 0 ]; then
        info "Package '$pkg' already installed at version $installed_ver."

        [ -n "$stars_temp" ] && rm -rf "$stars_temp"

        if [ "$IS_EXPLICIT" -eq 1 ]; then
            if is_in_world "$pkg"; then
                info "Package already in world set."
            else
                add_to_world "$pkg"
                info "Added to world set (marked as explicitly installed)."
            fi
        fi
        return 0
    fi

    # === BUILD THE PACKAGE ===
    info "[$pkg] Building version $recipe_ver (from $REPO_CONTEXT)..."

    if [ "$pkg" = "ccache" ] || [ "$pkg" = "dev-util/ccache" ]; then
        INSTALLING_CCACHE=1
        export INSTALLING_CCACHE
    fi

    # FIX: Use $pkg instead of $_pkg
    build_from_recipe_enhanced "$pkg" "$FORCE_CMD"

    unset INSTALLING_CCACHE

    # Cleanup expanded stars temp
    [ -n "$stars_temp" ] && rm -rf "$stars_temp"

    if [ "$IS_EXPLICIT" -eq 1 ]; then
        add_to_world "$pkg"
    fi
}

# === ASURA OVERLAY SYSTEM ===
# ASURA is a overlay on top of AOHARU
# explicit package from ASURA, dependencies from AOHARU
sync_pkg_asura() {
    _pkg="$1"
    FORCE_CMD=${2:-0}
    IS_EXPLICIT=${3:-0}

    if [ -z "$USER_RECIPE_RAW_URL" ]; then
        err "USER_RECIPE_RAW_URL not configured in $CONFIG_FILE. Cannot sync from ASURA."
    fi

    info "╔═══════════════════════════════════════════════════════════════════╗"
    info "║ ASURA: Astaraxia User Repository For all (Community Overlay)      ║"
    info "╠═══════════════════════════════════════════════════════════════════╣"
    info "║ Package:      $_pkg (from ASURA)                                  ║"
    info "║ Dependencies: Fetched from AOHARU (official, trusted)             ║"
    info "║ Security:     ASURA packages are user-contributed.                ║"
    info "╚═══════════════════════════════════════════════════════════════════╝"
    warn "Review package before installing: astral --inspect $_pkg"

    # Set ASURA context for the main package only
    REPO_CONTEXT="asura"

    sync_pkg_recursive "$_pkg" "$FORCE_CMD" "$IS_EXPLICIT" "asura"

    # Reset to AOHARU
    REPO_CONTEXT="aoharu"
    info "✓ ASURA sync complete, context reset to AOHARU"
}

build_from_recipe_enhanced() {
    _pkg="$1"
    FORCE_CMD=${2:-$FORCE_BUILD}
    BUILD_BINPKG=${3:-0}

    rpath=$(recipe_path "$_pkg") || err "recipe $_pkg not found"
    
    # Handle .stars format
    is_stars_recipe=0
    stars_temp=""
    
    if [ -f "$rpath" ]; then
        case "$rpath" in
            *.stars)
                is_stars_recipe=1
                info "[$_pkg] Using .stars recipe format"
                stars_temp="$TMPDIR/astral-stars-$_pkg-$$"
                expand_stars_recipe "$rpath" "$stars_temp"
                rpath="$stars_temp"
                trap "rm -rf '$stars_temp'" EXIT
                ;;
        esac
    fi
    
    recipe_ver="unknown"
    [ -f "$rpath/version" ] && recipe_ver=$(cat "$rpath/version")
    installed_ver=$(get_installed_ver "$_pkg")

    # Check if already installed
    if [ "$installed_ver" != "none" ]; then
        if [ "$installed_ver" = "$recipe_ver" ] && [ "$FORCE_CMD" -eq 0 ]; then
            info "Package '$pkg' is already installed at version $installed_ver. Skipping."
            return 0
        elif [ "$FORCE_CMD" -eq 1 ]; then
            info "Force rebuilding $pkg."
        else
            info "Upgrading '$pkg' from $installed_ver to $recipe_ver..."
        fi
    else
        info "Installing '$pkg' version $recipe_ver..."
    fi
    
    # Safety checks
    check_script_safety "$rpath/build" "$pkg"
    [ -f "$rpath/package" ] && check_script_safety "$rpath/package" "$pkg"
    [ -f "$rpath/post_install" ] && check_script_safety "$rpath/post_install" "$pkg"

    buildtmp="$TMPDIR/astral-build-$pkg-$$"
    mkdir -p "$buildtmp"
    if [ -d "$rpath" ]; then
        cp -a "$rpath"/* "$buildtmp"/ 2>/dev/null || true
    else
        err "Directory recipe structure not found for $pkg."
    fi
    cd "$buildtmp" || err "cd failed"

    trap "rm -rf '$buildtmp'" EXIT

    download_sources "$rpath" "$buildtmp"
    verify_checksums_and_extract "$pkg" "$rpath" "$buildtmp"

    # FEATURE 2: Take filesystem snapshot BEFORE build
    snapshot_before="$TMPDIR/astral-snapshot-before-$$"
    take_fs_snapshot "$snapshot_before"

    if [ -f "./build" ]; then
        chmod +x ./build || true
        PKGDIR="$buildtmp/pkg"
        mkdir -p "$PKGDIR"
        
        info "Starting isolated build for $pkg..."
        
        # FEATURE 1: Save state after configure
        save_build_state "$pkg" "configure" "$buildtmp"
        
        ( DESTDIR="$PKGDIR" ./build ) || err "build failed for $pkg"
        
        # FEATURE 1: Save state after build
        save_build_state "$pkg" "build" "$buildtmp"

        if [ -f "./package" ]; then
            info "Running package hook for $pkg..."
            ( DESTDIR="$PKGDIR" PKGDIR="$PKGDIR" ./package ) || err "package() failed for $pkg"
        fi
        
        # FEATURE 1: Save state after package
        save_build_state "$pkg" "package" "$buildtmp"

        # FEATURE 2: Take snapshot AFTER build and detect ghost files
        snapshot_after="$TMPDIR/astral-snapshot-after-$$"
        take_fs_snapshot "$snapshot_after"
        detect_ghost_files "$snapshot_before" "$snapshot_after" "$pkg"
        rm -f "$snapshot_before" "$snapshot_after"

        # FEATURE 4: Strip binaries if enabled
        strip_binaries "$PKGDIR" "$pkg"

        create_meta "$pkg" "$recipe_ver" "x86_64" "$PKGDIR"

        new_files=$(
            ( cd "$PKGDIR" && find . -mindepth 1 -print ) \
            | sed 's/^\.\///' \
            | grep -v '^\.astral-meta$' \
            || true
        )

        # FEATURE 3: Enhanced collision detection
        check_file_conflicts_advanced "$pkg" "$PKGDIR" "$FORCE_CMD"
        
        atomic_install "$pkg" "$PKGDIR" "$recipe_ver" "$rpath" "$new_files"
        
        if [ -f "$buildtmp/post_install" ]; then
            info "Running post_install hook for $pkg..."
            ( DESTDIR="$INSTALL_ROOT" PKGDIR="$PKGDIR" "$buildtmp/post_install" ) || info "Warning: post_install failed for $pkg"
        fi

        info "Successfully installed $pkg ($recipe_ver)."
    else
        err "Recipe $pkg has no build script"
    fi
    
    if [ -n "$stars_temp" ] && [ -d "$stars_temp" ]; then
        rm -rf "$stars_temp"
    fi
    
    trap - EXIT
    rm -rf "$buildtmp"
}

# Track explicitly installed packages
add_to_world() {
    pkg="$1"

    mkdir -p "$DB_DIR"
    touch "$WORLD_SET_FILE"

    # Add if not already present
    if ! grep -qxF "$pkg" "$WORLD_SET_FILE" 2>/dev/null; then
        printf '%s\n' "$pkg" >> "$WORLD_SET_FILE"
        return 0
    fi
    return 1
}

# Check if package is in world set
is_in_world() {
    pkg="$1"
    [ -f "$WORLD_SET_FILE" ] && grep -qxF "$pkg" "$WORLD_SET_FILE" 2>/dev/null
}

# Remove from world set
remove_from_world() {
    pkg="$1"

    if [ -f "$WORLD_SET_FILE" ]; then
        temp=$(mktemp)
        grep -vxF "$pkg" "$WORLD_SET_FILE" > "$temp" 2>/dev/null || true
        mv "$temp" "$WORLD_SET_FILE"
        info "Removed '$pkg' from world set"
    fi
}

# List world set
list_world() {
    if [ ! -f "$WORLD_SET_FILE" ]; then
        info "World set is empty (no explicitly installed packages)"
        return 0
    fi

    info "=== World Set (Explicitly Installed) ==="
    while IFS= read -r pkg; do
        [ -z "$pkg" ] && continue
        if is_pkg_installed "$pkg"; then
            ver=$(get_installed_ver "$pkg")
            printf "  ✓ %-20s (v%s)\n" "$pkg" "$ver"
        else
            printf "  ✗ %-20s (removed but still in world)\n" "$pkg"
        fi
    done < "$WORLD_SET_FILE"
}

update_repo() {
    repo="${1:-}"

    case "$repo" in
        aoharu|"")
            info "Updating Axia Official Repository Index (AOHARU)..."
            INDEX_FILE="$INDEX_FILE_AOHARU"
            INDEX_URL="${REPO_URL}astral.index"
            ;;
        asura)
            info "Updating Axia User Repository For All Indeks (ASURA)..."
            INDEX_FILE="$INDEX_FILE_ASURA"
            INDEX_URL="${USER_REPO_URL}/astral.index"
            ;;
        *)
            err "Unknown repository '$repo' for update"
            ;;
    esac

    if curl -f#SL "$INDEX_URL" -o "$INDEX_FILE"; then
        info "Database updated successfully."
    else
        err "Failed to download index from $INDEX_URL"
        return 1
    fi
}


# rewritten... hopes that it doesnt fucking explode
search_pkg() {
    query="$1"
    info "Searching for package '$query'..."

    # --- Local recipes ---
    info "--- Local Recipes ($RECIPES_DIR) ---"
    found_local=0
    for r in $(find "$RECIPES_DIR" -type d -mindepth 1 -maxdepth 2 2>/dev/null); do
        pkg_name=$(basename "$r")
        if printf '%s\n' "$pkg_name" | grep -iq "$query"; then
            ver="unknown"
            [ -f "$r/version" ] && ver=$(cat "$r/version")
            printf "L: %-20s (v%s) [%s]\n" "$pkg_name" "$ver" "$(basename "$(dirname "$r")")"
            found_local=1
        fi
    done
    [ "$found_local" -eq 0 ] && info "No local recipes found."


    # Remote indexes
    info "--- Remote Indexes ---"
    for idx in "$INDEX_FILE_AOHARU" "$INDEX_FILE_ASURA"; do
        [ -f "$idx" ] || continue
        while IFS= read -r line; do
            pkg_name=$(printf '%s' "$line" | awk '{print $1}')
            pkg_ver=$(printf '%s' "$line" | awk '{print $2}')
            repo_label=$(basename "$idx" | sed 's/index_//')
            if printf '%s\n' "$pkg_name" | grep -iq "$query"; then
                printf "R(%s): %-20s (v%s)\n" "$repo_label" "$pkg_name" "$pkg_ver"
            fi
        done < "$idx"
    done
}


show_pkg_info() {
    requested_pkg="$1"
    pkg_path=$(resolve_installed_path "$requested_pkg") 2>/dev/null || pkg_path="$requested_pkg"

    rpath=$(recipe_path "$requested_pkg") 2>/dev/null || rpath=""
    recipe_exists=0
    [ -n "$rpath" ] && recipe_exists=1

    info "--- Package Information: $pkg_path ---"

    installed_ver=$(get_installed_ver "$requested_pkg")
    printf "Installed Version: %s\n" "$installed_ver"
    if [ "$installed_ver" != "none" ]; then
        pkgdir="$DB_DIR/$pkg_path"
        installed_date="N/A"
        [ -f "$pkgdir/files" ] && installed_date=$(stat -c "%y" "$pkgdir/files" 2>/dev/null || echo "N/A")
        printf "Installed Path:    %s\n" "$pkgdir"
        printf "Installation Date: %s\n" "$installed_date"
        printf "Installed Files:   %s files\n" "$(wc -l < "$pkgdir/files" 2>/dev/null || echo 0)"

        installed_deps_list="None"
        installed_deps_count=0
        installed_deps=$(get_pkg_deps "$pkg_path" || true)
        if [ -n "$installed_deps" ]; then
             installed_deps_list=$(printf '%s' "$installed_deps" | tr '\n' ' ')
             installed_deps_count=$(printf '%s\n' "$installed_deps" | wc -l)
        fi
        printf "Dependencies (%s): %s\n" "$installed_deps_count" "$installed_deps_list"
    fi

    if [ "$recipe_exists" -eq 1 ]; then
        recipe_ver=$(cat "$rpath/version" 2>/dev/null || echo "unknown")
        printf "\nRecipe Found:      Yes\n"
        printf "Recipe Version:    %s\n" "$recipe_ver"
        printf "Recipe Path:       %s\n" "$rpath"

        recipe_deps_list="None"
        recipe_deps_count=0
        recipe_deps=$(get_pkg_deps "$requested_pkg" || true)
        if [ -n "$recipe_deps" ]; then
            recipe_deps_list=$(printf '%s' "$recipe_deps" | tr '\n' ' ')
            recipe_deps_count=$(printf '%s\n' "$recipe_deps" | wc -l)
        fi
        printf "Recipe Deps (%s):   %s\n" "$recipe_deps_count" "$recipe_deps_list"

        conflicts_list="None"
        conflicts_count=0
        if [ -f "$rpath/conflicts" ]; then
            filtered_conflicts=$(grep -v '^[[:space:]]*#' "$rpath/conflicts" | grep -E -v '^[[:space:]]*$' || true)
            conflicts_list=$(printf '%s' "$filtered_conflicts" | tr '\n' ' ')
            conflicts_count=$(printf '%s\n' "$filtered_conflicts" | wc -l)
        fi
        printf "Conflicts (%s):     %s\n" "$conflicts_count" "$conflicts_list"
        printf "Build Script:      %s\n" "$( [ -f "$rpath/build" ] && echo "Yes" || echo "No" )"
        printf "Package Script:    %s\n" "$( [ -f "$rpath/package" ] && echo "Yes" || echo "No" )"
        printf "Checksums:         %s\n" "$( [ -f "$rpath/checksums" ] && echo "Yes" || echo "No" )"

         # Display info file if it exists
         if [ -f "$rpath/info" ]; then
                 printf "\n--- Package Description ---\n"
                 cat "$rpath/info"
         fi
    else
        printf "\nRecipe Found:      No (Run 'astral -s %s' to fetch)\n" "$requested_pkg"
    fi
}

FILES_INDEX="$DB_DIR/.files.index"

rebuild_files_index() {
    info "Rebuilding file ownership index..."
    rm -f "$FILES_INDEX"
    touch "$FILES_INDEX"

    for pkgdir in "$DB_DIR"/*/* "$DB_DIR"/*; do
        [ -d "$pkgdir" ] || continue
        [ -f "$pkgdir/files" ] || continue

        pkg_path=$(printf '%s' "$pkgdir" | sed "s|^${DB_DIR}/||")

        while IFS= read -r file; do
            [ -z "$file" ] && continue
            # Format: filename|package_path
            printf '%s|%s\n' "$file" "$pkg_path" >> "$FILES_INDEX"
        done < "$pkgdir/files"
    done

    # Sort for faster lookups
    sort -u "$FILES_INDEX" -o "$FILES_INDEX"
    info "File index rebuilt ($(wc -l < "$FILES_INDEX") entries)"
}

get_file_owner() {
    file="$1"
    file_normalized=$(printf '%s' "$file" | sed 's|^/||')

    # Fast path: use index if it exists
    if [ -f "$FILES_INDEX" ]; then
        result=$(awk -F'|' -v f="$file_normalized" '$1 == f {print $2; exit}' "$FILES_INDEX" 2>/dev/null)
        if [ -n "$result" ] && [ "$result" != "" ]; then
            printf '%s' "$result"
            return 0
        fi
        return 1
    fi

    # Fallback: slow path (warns to rebuild index)
    warn "File index missing - using slow lookup. Run: astral --rebuild-index"

    for pkgdir in "$DB_DIR"/*/* "$DB_DIR"/*; do
        [ -d "$pkgdir" ] || continue
        [ -f "$pkgdir/files" ] || continue

        if grep -qxF "$file_normalized" "$pkgdir/files" 2>/dev/null; then
            pkg_path=$(printf '%s' "$pkgdir" | sed "s|^${DB_DIR}/||")
            printf '%s' "$pkg_path"
            return 0
        fi
    done

    return 1
}

update_files_index_for_pkg() {
    pkg_path="$1"

    [ ! -f "$FILES_INDEX" ] && return 0

    # Simple lock with timeout
    lock_dir="$FILES_INDEX.lock"
    max_wait=30
    wait_count=0

    while ! mkdir "$lock_dir" 2>/dev/null; do
        if [ $wait_count -ge $max_wait ]; then
            warn "Timeout waiting for file index lock, skipping update"
            return 1
        fi
        sleep 0.2
        wait_count=$((wait_count + 1))
    done

    # Remove old entries for this package
    temp=$(mktemp)
    grep -v "|${pkg_path}$" "$FILES_INDEX" > "$temp" 2>/dev/null || true
    mv "$temp" "$FILES_INDEX"

    # Add new entries
    pkgdir="$DB_DIR/$pkg_path"
    if [ -f "$pkgdir/files" ]; then
        while IFS= read -r file; do
            [ -z "$file" ] && continue
            printf '%s|%s\n' "$file" "$pkg_path" >> "$FILES_INDEX"
        done < "$pkgdir/files"
    fi

    # Release lock (always runs)
    rmdir "$lock_dir" 2>/dev/null || true
}

upgrade_all() {
    FORCE_CMD=${1:-0}  # 0 if not passed
    info "Starting full system upgrade (syncing all installed packages)..."

    count=0
    success_count=0

    find "$DB_DIR" -type f -name "version" -maxdepth 3 2>/dev/null |
    sed "s|^${DB_DIR}/||" | sed 's|/version$||' |
    while IFS= read -r pkg_path; do
        pkg=$(basename "$pkg_path")
        info "\n>>> Checking $pkg_path <<<"
        if sync_pkg_recursive "$pkg" "$FORCE_CMD"; then
            success_count=$((success_count + 1))
        else
            info "Warning: Failed to sync $pkg_path. Check logs."
        fi
        count=$((count + 1))
    done

    info "\nUpgrade process finished. Checked $count installed packages. $success_count updated/verified."
}

self_update() {
    TMPDIR="${TMPDIR:-/tmp}"
    tmp_file=$(mktemp "$TMPDIR/astral-new.XXXXXX") || err "mktemp failed"
    trap 'rm -f "$tmp_file"' EXIT

    branch="${1:-main}"
    case "$branch" in
        main)
            update_url="$SELF_UPDATE_URL_MAIN"
            info "Starting astral self-update from 'main' branch ($update_url)..."
        ;;
        cutting-edge)
            update_url="$SELF_UPDATE_URL_CUTTING_EDGE"
            info "Starting astral self-update from 'cutting-edge' branch ($update_url)..."
        ;;
        bleeding-edge)
            update_url="$SELF_UPDATE_URL_BLEEDING_EDGE"
            info "Starting astral self-update from 'bleeding-edge' branch ($update_url)..."
        ;;
        *)
            err "Unknown update branch '$branch'";
            return 1
        ;;
    esac

    command -v curl >/dev/null 2>&1 || { err "curl not found"; return 1; }

    if ! curl -f#SL "$update_url" -o "$tmp_file"; then
        err "Failed to download new astral script from $update_url"; return 1
    fi

    if ! head -n 1 "$tmp_file" | grep -qE '^#!'; then
        err "Downloaded file invalid (missing shebang)"; return 1
    fi

    chmod +x "$tmp_file"
    if mv -f "$tmp_file" "$SELF_UPDATE_PATH"; then
        info "Self-update successful!"
        trap - EXIT
    else
        err "Failed to replace $SELF_UPDATE_PATH"
        return 1
    fi
}

# --- SAFE REMOVAL HELPERS ---

remove_pkg_only() {
    pkg_path="$1"
    pkgdir="$DB_DIR/$pkg_path"
    [ -d "$pkgdir" ] || return 0

    info "Removing package database entry: $pkg_path"

    rpath=$(recipe_path "$(basename "$pkg_path")") 2>/dev/null || rpath=""
    if [ -n "$rpath" ] && [ -f "$rpath/post_remove" ]; then
        info "Running post_remove hook for $(basename "$pkg_path")..."
        ( "$rpath/post_remove" ) || info "Warning: post_remove hook failed for $pkg_path"
    fi

    if [ -f "$pkgdir/files" ]; then
        while IFS= read -r f; do
            [ -z "$f" ] && continue
            fullpath="$INSTALL_ROOT/$f"

            # Only remove files and symlinks, NEVER directories
            if [ -f "$fullpath" ] || [ -L "$fullpath" ]; then
                rm -f "$fullpath" 2>/dev/null || warn "Failed to remove: $fullpath"
            fi
            # Explicitly skip directories
        done < "$pkgdir/files"
    fi

    # Do NOT attempt to remove directories at all
    # This prevents deleting shared directories like /usr/bin, /usr/lib, etc. - *flashback of astral v0.1.0.0 removing my LFS /usr*

    rm -rf "$pkgdir"
    info "Removed $pkg_path from database (directories preserved for safety)."
}

removedep_pkg() {
    pkg="$1"
    initial_pkg_path=$(resolve_installed_path "$pkg") || err "package $pkg not installed"

    # Capture declared dependencies
    declared_deps=$(get_pkg_deps "$initial_pkg_path" || true)

    # Remove initial package
    remove_pkg_only "$initial_pkg_path"

    # Process dependencies with queue to avoid nested loops
    if [ -n "$declared_deps" ]; then
        dep_queue="$declared_deps"
        processed=""

        while [ -n "$dep_queue" ]; do
            # Get first dep from queue
            current_dep=$(printf '%s\n' "$dep_queue" | head -n1)
            dep_queue=$(printf '%s\n' "$dep_queue" | tail -n +2)

            current_dep=$(printf '%s' "$current_dep" | tr -d '[:space:]')
            [ -z "$current_dep" ] && continue

            # Skip if already processed
            case " $processed " in
                *" $current_dep "*) continue ;;
            esac
            processed="$processed $current_dep"

            # Check if host provides it
            if check_host_dependency "$current_dep"; then
                info "Dependency '$current_dep' provided by host; not removing."
                continue
            fi

            dep_path=$(resolve_installed_path "$current_dep") 2>/dev/null || continue

            if ! is_pkg_required "$dep_path"; then
                info "Removing orphan dependency: $dep_path"

                # Get subdeps before removal
                subdeps=$(get_pkg_deps "$dep_path" 2>/dev/null || true)

                # Remove the package
                remove_pkg_only "$dep_path"

                # Add subdeps to queue
                if [ -n "$subdeps" ]; then
                    dep_queue="$dep_queue $subdeps"
                fi
            else
                info "Keeping dependency $dep_path (still required)."
            fi
        done
    fi

    info "Orphan dependency cleanup complete."
}

remove_pkg() {
    requested_pkg="$1"
    pkg_path=$(resolve_installed_path "$requested_pkg") || err "package $requested_pkg not installed"
    remove_pkg_only "$pkg_path"
}

clean_cache() {
    info "Starting recipe cache cleanup in $RECIPES_DIR..."
    find "$RECIPES_DIR" -type d -mindepth 2 -maxdepth 2 2>/dev/null | while IFS= read -r recipe_dir; do
        pkg_name=$(basename "$recipe_dir")
        if is_pkg_installed "$pkg_name"; then
            info "Recipe for '$pkg_name' is installed. Skipping."
        else
            info "Removing cached recipe for '$pkg_name'..."
            rm -rf "$recipe_dir"
        fi
    done
    info "Cache cleanup complete."
}

list_installed() {
    if [ ! -d "$DB_DIR" ] || [ -z "$(ls -A "$DB_DIR" 2>/dev/null)" ]; then
        info "No packages currently installed."
        return 0
    fi
    info "--- Installed Packages ---"
    last_category=""
    find "$DB_DIR" -type f -name "version" -maxdepth 3 2>/dev/null |
    sed "s|^${DB_DIR}/||" | sed 's|/version$||' | sort |
    while IFS= read -r pkg_path; do
        pkg_name=$(basename "$pkg_path")
        category=$(dirname "$pkg_path")
        pkg_ver=""
        if [ "$category" = "." ] || [ -z "$category" ] || [ "$category" = "/" ]; then
            category="Uncategorized"
        fi
        if [ "$category" != "$last_category" ]; then
            printf '%s\n' "$category"
            last_category="$category"
        fi
        if [ -f "$DB_DIR/$pkg_path/version" ]; then
             pkg_ver=$(cat "$DB_DIR/$pkg_path/version")
        fi
        printf "|- %-15s (v%s)\n" "$pkg_name" "$pkg_ver"
    done
    printf '\n'
}
# Add after list_installed() function

check_deps_tree() {
    pkg="$1"
    prefix="${2:-}"
    visited="${3:-}"

    is_visited=0
    for v in $visited; do
        [ "$v" = "$pkg" ] && is_visited=1 && break
    done

    if [ $is_visited -eq 1 ]; then
        printf '%s%s [CIRCULAR]\n' "$prefix" "$pkg"
        return 0
    fi

    visited="$visited $pkg"

    if is_pkg_installed "$pkg"; then
        installed_ver=$(get_installed_ver "$pkg")
        printf '%s%s [installed: v%s]\n' "$prefix" "$pkg" "$installed_ver"
    else
        if check_host_dependency "$pkg"; then
            printf '%s%s [host-provided]\n' "$prefix" "$pkg"
            return 0
        fi

        if recipe_path "$pkg" >/dev/null 2>&1; then
            rpath=$(recipe_path "$pkg")
            recipe_ver=$(cat "$rpath/version" 2>/dev/null || echo "unknown")
            printf '%s%s [available: v%s]\n' "$prefix" "$pkg" "$recipe_ver"
        else
            printf '%s%s [NOT FOUND!]\n' "$prefix" "$pkg"
            return 0
        fi
    fi

    deps=$(get_pkg_deps "$pkg" || true)
    [ -z "$deps" ] && return 0

    printf '%s\n' "$deps" | while IFS= read -r dep; do
        dep=$(printf '%s' "$dep" | tr -d '[:space:]')
        [ -z "$dep" ] && continue
        check_deps_tree "$dep" "$prefix  ├─ " "$visited"
    done
}

preview_install() {
    pkg="$1"

    info "=== Install Preview for '$pkg' ==="
    info "Computing dependency graph..."

    # Collect all dependencies recursively
    all_deps=""
    to_install=""
    already_installed=""

    # Make this a proper recursive function
    collect_deps_recursive() {
        local p="$1"
        local indent="${2:-}"

        # Check if already processed
        case " $all_deps " in
            *" $p "*) return 0 ;;
        esac

        all_deps="$all_deps $p"

        # Check install status
        if is_pkg_installed "$p"; then
            ver=$(get_installed_ver "$p")
            printf '%s[installed] %s-%s\n' "$indent" "$p" "$ver"
            already_installed="$already_installed $p"
        elif check_host_dependency "$p"; then
            printf '%s[host] %s\n' "$indent" "$p"
        else
            printf '%s[new] %s\n' "$indent" "$p"
            to_install="$to_install $p"
        fi

        # Get dependencies
        deps=$(get_pkg_deps "$p" 2>/dev/null || true)
        if [ -n "$deps" ]; then
            printf '%s\n' "$deps" | while IFS= read -r dep; do
                dep=$(printf '%s' "$dep" | tr -d '[:space:]')
                [ -z "$dep" ] && continue
                collect_deps_recursive "$dep" "$indent  "
            done
        fi
    }

    collect_deps_recursive "$pkg" ""

    # Summary
    info ""
    info "=== Summary ==="

    new_count=$(printf '%s' "$to_install" | wc -w)
    installed_count=$(printf '%s' "$already_installed" | wc -w)

    info "Packages to install: $new_count"
    info "Already installed:   $installed_count"

    if [ "$new_count" -gt 0 ]; then
        info ""
        info "New packages:"
        for p in $to_install; do
            info "  - $p"
        done
    fi
}

show_deps() {
    pkg="$1"
    pkg=$(sanitize_pkg_name "$pkg")
    info "=== Dependency Tree for '$pkg' ==="
    check_deps_tree "$pkg" "" ""
    info ""
}

show_why_installed() {
    target_pkg="$1"

    if ! is_pkg_installed "$target_pkg"; then
        info "Package '$target_pkg' is not installed."
        return 1
    fi

    info "=== Why is '$target_pkg' installed? ==="

    # Check if in world set
    if is_in_world "$target_pkg"; then
        info "✓ Explicitly installed (in world set)"
    fi

    # Find packages that depend on it
    dependents=""
    for pkgdir in "$DB_DIR"/*/* "$DB_DIR"/*; do
        [ -d "$pkgdir" ] || continue
        pkg_path=$(printf '%s' "$pkgdir" | sed "s|^${DB_DIR}/||")
        pkg_name=$(basename "$pkg_path")

        deps=$(get_pkg_deps "$pkg_name" 2>/dev/null || true)
        if printf '%s\n' "$deps" | grep -qxF "$target_pkg"; then
            dependents="$dependents $pkg_name"
            info "  ← Required by: $pkg_name"
        fi
    done

    if [ -z "$dependents" ] && ! is_in_world "$target_pkg"; then
        warn "Package is installed but not in world and nothing depends on it (orphan!)"
    fi
}

autoremove_orphans() {
    info "=== Finding Orphaned Packages ==="

    orphans=""

    for pkgdir in "$DB_DIR"/*/* "$DB_DIR"/*; do
        [ -d "$pkgdir" ] || continue
        pkg_path=$(printf '%s' "$pkgdir" | sed "s|^${DB_DIR}/||")
        pkg_name=$(basename "$pkg_path")

        # Skip if in world
        is_in_world "$pkg_name" && continue

        # Skip if required by another package
        is_pkg_required "$pkg_path" && continue

        # Found orphan
        orphans="$orphans $pkg_name"
        info "  Found orphan: $pkg_name"
    done

    if [ -z "$orphans" ]; then
        info "✓ No orphaned packages found"
        return 0
    fi

    info ""
    info "Orphaned packages to remove:"
    for pkg in $orphans; do
        info "  - $pkg"
    done

    if [ "$DRY_RUN" -eq 1 ]; then
        info "[DRY-RUN] Would remove orphaned packages"
        return 0
    fi

    info ""
    info "Remove these packages? (y/N)"
    read -r response

    case "$response" in
        [Yy]*)
            for pkg in $orphans; do
                info "Removing orphan: $pkg"
                remove_pkg "$pkg"
            done
            info "✓ Orphan removal complete"
            ;;
        *)
            info "Cancelled"
            ;;
    esac
}

check_system_deps() {
    info "=== Checking System Dependencies ==="
    broken_count=0

    pkgs_tmp=$(mktemp "$TMPDIR/astral-depcheck.XXXXXX") || err "mktemp failed"
    find "$DB_DIR" -type f -name "version" -maxdepth 3 2>/dev/null | \
        sed "s|^${DB_DIR}/||" | sed 's|/version$||' > "$pkgs_tmp"

    while IFS= read -r pkg_path; do
        pkg_name=$(basename "$pkg_path")
        deps=$(get_pkg_deps "$pkg_path" || true)
        [ -z "$deps" ] && continue

        has_broken=0
        printf '%s\n' "$deps" | while IFS= read -r dep; do
            dep=$(printf '%s' "$dep" | tr -d '[:space:]')
            [ -z "$dep" ] && continue

            if ! is_pkg_installed "$dep" && ! check_host_dependency "$dep"; then
                if [ $has_broken -eq 0 ]; then
                    info "✗ $pkg_name has broken dependencies:"
                    has_broken=1
                fi
                info "  - Missing: $dep"
            fi
        done

        [ $has_broken -eq 1 ] && broken_count=$((broken_count + 1))
    done < "$pkgs_tmp"
    rm -f "$pkgs_tmp"

    if [ $broken_count -eq 0 ]; then
        info "✓ No broken dependencies found!"
    else
        info "✗ Found packages with broken dependencies."
    fi
}
# === Build State Management ===
# Save build state
save_build_state() {
    pkg="$1"
    stage="$2"  # configure, build, package, complete
    buildtmp="$3"
    
    state_file="$buildtmp/.astral_build_state"
    
    cat > "$state_file" <<EOF
PACKAGE=$pkg
STAGE=$stage
TIMESTAMP=$(date +%s)
VERSION=$recipe_ver
EOF
    
    info "[$pkg] Build state saved: $stage"
}

# Load build state
load_build_state() {
    buildtmp="$1"
    state_file="$buildtmp/.astral_build_state"
    
    if [ -f "$state_file" ]; then
        . "$state_file"
        return 0
    fi
    
    return 1
}

# Resume build from saved state
resume_build() {
    pkg="$1"
    
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                    Resuming Build: $pkg"
    info "╚════════════════════════════════════════════════════════════════╝"
    info ""
    
    # Find build directory
    buildtmp=$(find "$TMPDIR" -maxdepth 1 -type d -name "astral-build-${pkg}-*" 2>/dev/null | head -n1)
    
    if [ -z "$buildtmp" ]; then
        err "No interrupted build found for '$pkg'. Start fresh with: astral -S $pkg"
    fi
    
    if ! load_build_state "$buildtmp"; then
        err "Build state file not found in $buildtmp"
    fi
    
    info "Found interrupted build:"
    info "  Package:   $PACKAGE"
    info "  Stage:     $STAGE"
    info "  Timestamp: $(date -d "@$TIMESTAMP" 2>/dev/null || date -r "$TIMESTAMP")"
    info ""
    
    cd "$buildtmp" || err "Failed to enter build directory"
    
    # Resume from appropriate stage
    case "$STAGE" in
        configure)
            info "Resuming from: make"
            if [ -f "./build" ]; then
                ( cd "$(find . -maxdepth 1 -type d ! -name . | head -n1)" && make -j$(nproc) )
                save_build_state "$pkg" "build" "$buildtmp"
            fi
            ;;
        build)
            info "Resuming from: package/install"
            # Continue to package stage
            ;;
        package)
            info "Build already packaged, installing..."
            # Continue to install
            ;;
        *)
            err "Unknown build stage: $STAGE"
            ;;
    esac
    
    info "✓ Build resumed successfully"
}

# === Ghost File Detector (pls workk) ===
# Take filesystem snapshot
take_fs_snapshot() {
    snapshot_file="$1"
    
    info "Taking filesystem snapshot..."
    
    # Capture timestamps and paths of critical directories
    {
        find /etc -maxdepth 3 -type f -printf "%T@ %p\n" 2>/dev/null
        find /usr/bin -maxdepth 1 -type f -printf "%T@ %p\n" 2>/dev/null
        find /usr/lib -maxdepth 2 -type f -printf "%T@ %p\n" 2>/dev/null
        find /usr/lib64 -maxdepth 2 -type f -printf "%T@ %p\n" 2>/dev/null
        find /lib -maxdepth 2 -type f -printf "%T@ %p\n" 2>/dev/null
        find /lib64 -maxdepth 2 -type f -printf "%T@ %p\n" 2>/dev/null
    } | sort > "$snapshot_file"
}

# Detect ghost files (files created outside $PKGDIR)
detect_ghost_files() {
    before_snapshot="$1"
    after_snapshot="$2"
    pkg="$3"
    
    info "Checking for ghost files (files installed outside \$PKGDIR)..."
    
    # Compare snapshots
    ghost_files=$(comm -13 "$before_snapshot" "$after_snapshot" | awk '{print $2}')
    
    if [ -n "$ghost_files" ]; then
        warn "╔════════════════════════════════════════════════════════════════╗"
        warn "║  GHOST FILES DETECTED: Files modified outside \$PKGDIR!        ║"
        warn "╚════════════════════════════════════════════════════════════════╝"
        warn ""
        warn "Package '$pkg' modified files directly on the system:"
        warn ""
        
        printf '%s\n' "$ghost_files" | while read -r file; do
            warn "  ⚠️  $file"
        done
        
        warn ""
        warn "This is a packaging bug! The build script should install to \$PKGDIR,"
        warn "not directly to the system."
        warn ""
        warn "These files are NOT tracked by Astral and may cause issues."
        warn ""
        
        # Ask if user wants to continue
        if [ "$FORCE_BUILD" -eq 0 ]; then
            printf "Continue anyway? (y/N): "
            read -r response
            case "$response" in
                [Yy]*) return 0 ;;
                *) err "Installation aborted due to ghost files" ;;
            esac
        else
            warn "Continuing due to --force flag"
        fi
    else
        info "  ✓ No ghost files detected (clean install)"
    fi
}

# === Collision Protector ===

# Check for file collisions (improved version that's already in your code)
check_file_conflicts_advanced() {
    pkg="$1"
    pkgdir="$2"
    force="$3"
    
    conflict_file="$TMPDIR/conflicts.$$"
    collision_file="$TMPDIR/collisions.$$"

    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                      Collision Detection                       ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    info ""
    info "Checking for file conflicts and collisions..."

    [ ! -d "$pkgdir" ] && return 0

    conflicts=0
    collisions=0

    ( cd "$pkgdir" && find . -type f -o -type l ) | sed 's|^\./||' | while IFS= read -r file; do
        [ -z "$file" ] && continue
        [ "$file" = ".astral-meta" ] && continue

        target_path="$INSTALL_ROOT/$file"

        # Skip if file doesn't exist yet
        [ ! -e "$target_path" ] && [ ! -L "$target_path" ] && continue

        # Check who owns this file
        owner=$(get_file_owner "$file") || owner=""

        if [ -n "$owner" ]; then
            owner_name=$(basename "$owner")
            if [ "$owner_name" != "$pkg" ]; then
                # Check if files are identical (collision vs conflict)
                if cmp -s "$pkgdir/$file" "$target_path" 2>/dev/null; then
                    # Same content = collision (less severe)
                    printf "COLLISION|%s|%s\n" "$file" "$owner"
                else
                    # Different content = conflict (severe)
                    printf "CONFLICT|%s|%s\n" "$file" "$owner"
                fi
            fi
        fi
    done > "$conflict_file"

    # Separate conflicts and collisions
    grep "^CONFLICT" "$conflict_file" | cut -d'|' -f2,3 > "$collision_file" || true
    conflicts=$(wc -l < "$collision_file" 2>/dev/null || echo 0)
    
    grep "^COLLISION" "$conflict_file" | cut -d'|' -f2,3 >> "$collision_file" || true
    collisions=$(grep -c "^COLLISION" "$conflict_file" 2>/dev/null || echo 0)

    # Display conflicts
    if [ "$conflicts" -gt 0 ]; then
        warn "╔════════════════════════════════════════════════════════════════╗"
        warn "║                   FILE CONFLICTS DETECTED                      ║"
        warn "╚════════════════════════════════════════════════════════════════╝"
        warn ""
        warn "The following files are owned by other packages (DIFFERENT content):"
        warn ""
        
        grep "^CONFLICT" "$conflict_file" | while IFS='|' read -r type file owner; do
            warn "  ✗ CONFLICT: $file"
            warn "    Currently owned by: $owner"
        done
        
        if [ "$force" -eq 0 ]; then
            rm -f "$conflict_file" "$collision_file"
            err "Aborting installation due to file conflicts. Use --force to override."
        fi
    fi
    
    # Display collisions (same content)
    if [ "$collisions" -gt 0 ]; then
        info ""
        info "File collisions detected (same content, safe):"
        info ""
        
        grep "^COLLISION" "$conflict_file" | while IFS='|' read -r type file owner; do
            info "  ⚠️  $file (also in $owner)"
        done
        
        info ""
        info "These files are identical and can be safely overwritten."
    fi

    if [ "$conflicts" -eq 0 ] && [ "$collisions" -eq 0 ]; then
        info "  ✓ No conflicts or collisions detected"
    fi

    rm -f "$conflict_file" "$collision_file"
}

# === Auto-stripp ===
# Strip binaries and libraries
strip_binaries() {
    pkgdir="$1"
    pkg="$2"
    
    # Check if stripping is enabled
    if [ "$STRIP_BINARIES" != "yes" ]; then
        return 0
    fi
    
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                 Stripping Debug Symbols                       ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    info ""
    
    stripped_count=0
    
    # Strip binaries
    find "$pkgdir" -type f -executable 2>/dev/null | while read -r file; do
        if file "$file" | grep -q 'ELF.*executable'; then
            if strip --strip-unneeded "$file" 2>/dev/null; then
                info "  Stripped: $(basename "$file")"
                stripped_count=$((stripped_count + 1))
            fi
        fi
    done
    
    # Strip shared libraries
    find "$pkgdir" -type f -name "*.so*" 2>/dev/null | while read -r file; do
        if file "$file" | grep -q 'ELF.*shared object'; then
            if strip --strip-unneeded "$file" 2>/dev/null; then
                info "  Stripped: $(basename "$file")"
                stripped_count=$((stripped_count + 1))
            fi
        fi
    done
    
    # Strip static libraries
    find "$pkgdir" -type f -name "*.a" 2>/dev/null | while read -r file; do
        if strip --strip-debug "$file" 2>/dev/null; then
            info "  Stripped: $(basename "$file")"
            stripped_count=$((stripped_count + 1))
        fi
    done
    
    if [ $stripped_count -gt 0 ]; then
        info ""
        info "✓ Stripped $stripped_count files"
    else
        info "  No files needed stripping"
    fi
}

# === Lock SIAL ===
acquire_lock() {
    lockdir=$(dirname "$LOCK_FILE")
    mkdir -p "$lockdir" 2>/dev/null || true

    # Try to acquire lock immediately
    if mkdir "$LOCK_FILE.d" 2>/dev/null; then
        printf '%s\n' $$ > "$LOCK_FILE.d/pid"
        trap 'release_lock; exit 130' INT TERM
        return 0
    fi

    # Lock exists - check if process is alive
    if [ -f "$LOCK_FILE.d/pid" ]; then
        lock_pid=$(cat "$LOCK_FILE.d/pid" 2>/dev/null || printf '')

        if [ -n "$lock_pid" ]; then
            # Check if process exists
            if kill -0 "$lock_pid" 2>/dev/null; then
                # Process is alive - get process info
                if command -v ps >/dev/null 2>&1; then
                    process_info=$(ps -p "$lock_pid" -o comm= 2>/dev/null || printf 'unknown')
                    err "Another instance of astral is already running (PID: $lock_pid, Process: $process_info)"
                else
                    err "Another instance of astral is already running (PID: $lock_pid)"
                fi
            else
                # Process is dead - remove stale lock
                warn "Removing stale lock from dead process (PID: $lock_pid)"
                rm -rf "$LOCK_FILE.d"

                # Try again
                if mkdir "$LOCK_FILE.d" 2>/dev/null; then
                    printf '%s\n' $$ > "$LOCK_FILE.d/pid"
                    trap 'release_lock; exit 130' INT TERM
                    return 0
                else
                    err "Failed to acquire lock after removing stale lock"
                fi
            fi
        else
            # PID file is empty or unreadable - remove corrupt lock
            warn "Removing corrupt lock (no PID found)"
            rm -rf "$LOCK_FILE.d"

            # Try again
            if mkdir "$LOCK_FILE.d" 2>/dev/null; then
                printf '%s\n' $$ > "$LOCK_FILE.d/pid"
                trap 'release_lock; exit 130' INT TERM
                return 0
            else
                err "Failed to acquire lock after removing corrupt lock"
            fi
        fi
    else
        # Lock directory exists but no PID file
        warn "Removing incomplete lock (no PID file)"
        rm -rf "$LOCK_FILE.d"

        # Try again
        if mkdir "$LOCK_FILE.d" 2>/dev/null; then
            printf '%s\n' $$ > "$LOCK_FILE.d/pid"
            trap 'release_lock; exit 130' INT TERM
            return 0
        else
            err "Failed to acquire lock after removing incomplete lock"
        fi
    fi
}

release_lock() {
    rm -rf "$LOCK_FILE.d" 2>/dev/null || true
}

show_ccache_stats() {
    if ! command -v ccache >/dev/null 2>&1; then
        err "ccache is not installed"
    fi

    info "=== ccache Statistics ==="
    ccache -s
}

clear_ccache() {
    if ! command -v ccache >/dev/null 2>&1; then
        err "ccache is not installed"
    fi

    info "Clearing ccache..."
    ccache -C
    info "ccache cleared"
}

# === STORE HASH COMPUTATION ===
compute_store_hash() {
    pkg="$1"
    ver="$2"
    rpath="$3"
    
    # Collect inputs for hashing
    hash_input=""
    
    # 1. Package name and version
    hash_input="${hash_input}${pkg}-${ver}"
    
    # 2. Build script content
    if [ -f "$rpath/build" ]; then
        hash_input="${hash_input}$(cat "$rpath/build")"
    fi
    
    # 3. Dependencies (sorted for consistency)
    deps=$(get_pkg_deps "$pkg" 2>/dev/null | sort)
    hash_input="${hash_input}${deps}"
    
    # 4. Build environment (only relevant vars)
    hash_input="${hash_input}${CFLAGS}${MAKEFLAGS}"
    
    # Compute SHA256 hash (first 16 chars for readability)
    echo "$hash_input" | sha256sum | cut -c1-16
}

# === STORE PATH MANAGEMENT ===
get_store_path() {
    pkg="$1"
    ver="$2"
    hash="$3"
    printf '%s/%s-%s-%s\n' "$ASTRAL_STORE" "$pkg" "$ver" "$hash"
}

store_path_exists() {
    store_path="$1"
    [ -d "$store_path" ] && [ -f "$store_path/.astral-store-meta" ]
}

# === PROFILE MANAGEMENT ===
init_profile() {
    profile_name="${1:-default}"
    profile_path="$ASTRAL_PROFILES/$profile_name"
    
    mkdir -p "$profile_path"
    mkdir -p "$ASTRAL_GENERATIONS"
    
    # Create generation-1 if doesn't exist
    if [ ! -d "$profile_path/generation-1" ]; then
        mkdir -p "$profile_path/generation-1/bin"
        mkdir -p "$profile_path/generation-1/lib"
        mkdir -p "$profile_path/generation-1/include"
        mkdir -p "$profile_path/generation-1/share"
        
        # Track generation metadata
        cat > "$profile_path/generation-1/.meta" <<EOF
created=$(date +%s)
packages=
EOF
    fi
    
    # Set current if not exists
    if [ ! -L "$profile_path/current" ]; then
        ln -sf "generation-1" "$profile_path/current"
    fi
}

get_current_generation() {
    profile="${1:-default}"
    profile_path="$ASTRAL_PROFILES/$profile"
    
    if [ -L "$profile_path/current" ]; then
        basename "$(readlink "$profile_path/current")" | sed 's/generation-//'
    else
        echo "1"
    fi
}

create_new_generation() {
    profile="${1:-default}"
    profile_path="$ASTRAL_PROFILES/$profile"
    
    current=$(get_current_generation "$profile")
    next=$((current + 1))
    
    info "Creating generation $next for profile '$profile'..."
    
    # Copy current generation structure (hard links for efficiency)
    cp -al "$profile_path/generation-$current" "$profile_path/generation-$next" 2>/dev/null || \
        mkdir -p "$profile_path/generation-$next"
    
    # Update metadata
    cat > "$profile_path/generation-$next/.meta" <<EOF
created=$(date +%s)
previous=$current
packages=
EOF
    
    echo "$next"
}

switch_to_generation() {
    profile="${1:-default}"
    gen_number="$2"
    profile_path="$ASTRAL_PROFILES/$profile"
    
    gen_path="$profile_path/generation-$gen_number"
    
    if [ ! -d "$gen_path" ]; then
        err "Generation $gen_number does not exist for profile '$profile'"
    fi
    
    info "Switching to generation $gen_number..."
    
    # Atomic switch
    ln -sf "generation-$gen_number" "$profile_path/current.tmp"
    mv -f "$profile_path/current.tmp" "$profile_path/current"
    
    # Update system symlinks
    update_system_symlinks "$profile"
    
    info "✓ Switched to generation $gen_number"
}

# === SYMLINK MANAGEMENT ===
link_package_to_generation() {
    pkg="$1"
    store_path="$2"
    profile="${3:-default}"
    generation="$4"
    
    profile_path="$ASTRAL_PROFILES/$profile"
    gen_path="$profile_path/generation-$generation"
    
    info "Linking $pkg to generation $generation..."
    
    # Create symlinks for each directory
    for subdir in bin lib include share etc; do
        if [ -d "$store_path/$subdir" ]; then
            mkdir -p "$gen_path/$subdir"
            
            # Link all files in subdir
            find "$store_path/$subdir" -mindepth 1 -maxdepth 1 | while read -r item; do
                item_name=$(basename "$item")
                
                # Remove old link if exists
                rm -f "$gen_path/$subdir/$item_name"
                
                # Create new link
                ln -sf "$item" "$gen_path/$subdir/$item_name"
            done
        fi
    done
    
    # Update generation metadata
    pkg_entry="$pkg:$store_path"
    if ! grep -q "^$pkg:" "$gen_path/.meta" 2>/dev/null; then
        echo "$pkg_entry" >> "$gen_path/.meta"
    fi
}

update_system_symlinks() {
    profile="${1:-default}"
    profile_path="$ASTRAL_PROFILES/$profile"
    current_gen="$profile_path/current"
    
    # Update /usr/local to point to profile
    # (safer than /usr to avoid conflicts)
    for subdir in bin lib include share; do
        system_dir="$INSTALL_ROOT/usr/local/$subdir"
        gen_dir="$current_gen/$subdir"
        
        if [ -d "$gen_dir" ]; then
            mkdir -p "$system_dir"
            
            # Remove broken symlinks
            find "$system_dir" -type l ! -exec test -e {} \; -delete 2>/dev/null || true
            
            # Link new files
            find "$gen_dir" -mindepth 1 -maxdepth 1 -type l | while read -r link; do
                link_name=$(basename "$link")
                rm -f "$system_dir/$link_name"
                ln -sf "$link" "$system_dir/$link_name"
            done
        fi
    done
}

# === ENHANCED BUILD FUNCTION ===
build_to_store() {
    pkg="$1"
    recipe_ver="$2"
    rpath="$3"
    
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║           Building $pkg to Store (Nix-like mode)              ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    
    # Compute store hash
    store_hash=$(compute_store_hash "$pkg" "$recipe_ver" "$rpath")
    store_path=$(get_store_path "$pkg" "$recipe_ver" "$store_hash")
    
    info "Store path: $store_path"
    info "Store hash: $store_hash"
    
    # Check if already built
    if store_path_exists "$store_path"; then
        info "✓ Package already in store, linking..."
        
        # Link to current generation
        profile="default"
        gen=$(get_current_generation "$profile")
        link_package_to_generation "$pkg" "$store_path" "$profile" "$gen"
        update_system_symlinks "$profile"
        
        return 0
    fi
    
    # Build in temporary location
    buildtmp="$TMPDIR/astral-store-build-$pkg-$$"
    mkdir -p "$buildtmp"
    
    # Copy recipe
    if [ -d "$rpath" ]; then
        cp -a "$rpath"/* "$buildtmp"/ 2>/dev/null || true
    fi
    
    cd "$buildtmp" || err "cd failed"
    trap "rm -rf '$buildtmp'" EXIT
    
    # Download and verify sources
    download_sources "$rpath" "$buildtmp"
    verify_checksums_and_extract "$pkg" "$rpath" "$buildtmp"
    
    # Build with store-specific environment
    PKGDIR="$buildtmp/pkg"
    mkdir -p "$PKGDIR"
    
    # Set reproducible environment
    export SOURCE_DATE_EPOCH="${SOURCE_DATE_EPOCH:-$(date +%s)}"
    export ASTRAL_STORE_PATH="$store_path"
    
    info "Building with reproducible environment..."
    info "  SOURCE_DATE_EPOCH=$SOURCE_DATE_EPOCH"
    
    if [ -f "./build" ]; then
        chmod +x ./build || true
        ( DESTDIR="$PKGDIR" PKGDIR="$PKGDIR" ./build ) || err "build failed for $pkg"
    fi
    
    if [ -f "./package" ]; then
        ( DESTDIR="$PKGDIR" PKGDIR="$PKGDIR" ./package ) || err "package() failed for $pkg"
    fi
    
    # Install to store (atomic)
    info "Installing to store: $store_path"
    mkdir -p "$(dirname "$store_path")"
    
    # Use temporary directory then rename (atomic)
    temp_store="$store_path.tmp.$$"
    mv "$PKGDIR" "$temp_store" || err "Failed to move to store"
    
    # Add store metadata
    cat > "$temp_store/.astral-store-meta" <<EOF
package=$pkg
version=$recipe_ver
store_hash=$store_hash
build_time=$(date +%s)
builder=$(whoami)
EOF
    
    # Atomic rename
    mv "$temp_store" "$store_path" || err "Failed to finalize store path"
    
    info "✓ Package installed to store"
    
    # Create new generation and link
    profile="default"
    new_gen=$(create_new_generation "$profile")
    link_package_to_generation "$pkg" "$store_path" "$profile" "$new_gen"
    switch_to_generation "$profile" "$new_gen"
    
    # Cleanup
    rm -rf "$buildtmp"
    trap - EXIT
    
    info "✓ Package $pkg-$recipe_ver built and linked (generation $new_gen)"
}

# === GARBAGE COLLECTION ===
collect_garbage_store() {
    dry_run="${1:-0}"
    
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                    Store Garbage Collection                    ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    
    # Find all referenced store paths
    referenced=$(mktemp "$TMPDIR/astral-gc-refs.XXXXXX")
    
    # 1. From all profiles and generations
    find "$ASTRAL_PROFILES" -type l 2>/dev/null | while read -r link; do
        target=$(readlink -f "$link" 2>/dev/null || true)
        case "$target" in
            "$ASTRAL_STORE"*) echo "$target" ;;
        esac
    done >> "$referenced"
    
    # 2. From GC roots
    if [ -d "$ASTRAL_STORE/gcroots" ]; then
        find "$ASTRAL_STORE/gcroots" -type l 2>/dev/null | while read -r link; do
            readlink -f "$link" 2>/dev/null || true
        done >> "$referenced"
    fi
    
    # Sort and unique
    sort -u "$referenced" -o "$referenced"
    
    ref_count=$(wc -l < "$referenced")
    info "Found $ref_count referenced store paths"
    
    # Find all store paths
    total_count=0
    removed_count=0
    
    find "$ASTRAL_STORE" -maxdepth 1 -type d | while read -r store_path; do
        [ "$store_path" = "$ASTRAL_STORE" ] && continue
        [ "$(basename "$store_path")" = "gcroots" ] && continue
        
        total_count=$((total_count + 1))
        
        if ! grep -qF "$store_path" "$referenced"; then
            if [ "$dry_run" -eq 1 ]; then
                info "[DRY-RUN] Would remove: $(basename "$store_path")"
            else
                info "Removing: $(basename "$store_path")"
                rm -rf "$store_path"
            fi
            removed_count=$((removed_count + 1))
        fi
    done
    
    rm -f "$referenced"
    
    info ""
    info "Garbage collection complete:"
    info "  Total paths:     $total_count"
    info "  Referenced:      $ref_count"
    info "  Removed:         $removed_count"
}

# === ROLLBACK SUPPORT ===
rollback_profile() {
    profile="${1:-default}"
    
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                      Rolling Back Profile                      ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    
    current=$(get_current_generation "$profile")
    prev=$((current - 1))
    
    if [ $prev -lt 1 ]; then
        err "No previous generation to rollback to"
    fi
    
    info "Current generation: $current"
    info "Rolling back to:    $prev"
    
    switch_to_generation "$profile" "$prev"
    
    info "✓ Rollback complete"
}

list_generations_store() {
    profile="${1:-default}"
    profile_path="$ASTRAL_PROFILES/$profile"
    
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                    Profile Generations                         ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    
    current=$(get_current_generation "$profile")
    
    find "$profile_path" -maxdepth 1 -type d -name "generation-*" | sort -V | while read -r gen_dir; do
        gen_num=$(basename "$gen_dir" | sed 's/generation-//')
        
        if [ "$gen_num" = "$current" ]; then
            marker="→"
        else
            marker=" "
        fi
        
        # Read metadata
        if [ -f "$gen_dir/.meta" ]; then
            created=$(grep '^created=' "$gen_dir/.meta" | cut -d= -f2)
            created_date=$(date -d "@$created" 2>/dev/null || date -r "$created")
            pkg_count=$(grep -v '^created=' "$gen_dir/.meta" | grep -v '^previous=' | wc -l)
        else
            created_date="unknown"
            pkg_count=0
        fi
        
        printf "%s Generation %2d: %s (%d packages)\n" "$marker" "$gen_num" "$created_date" "$pkg_count"
        
        # Show packages in this generation
        if [ -f "$gen_dir/.meta" ]; then
            grep -v '^created=' "$gen_dir/.meta" | grep -v '^previous=' | while IFS=: read -r pkg store; do
                printf "     - %s\n" "$pkg"
            done
        fi
    done
}

# === WRAPPER FOR EXISTING SYNC ===
sync_pkg_with_store() {
    pkg="$1"
    force="${2:-0}"
    
    if [ "$USE_STORE_MODE" = "yes" ]; then
        info "Using store-based installation for $pkg"
        
        # Initialize profile if needed
        init_profile "default"
        
        # Fetch recipe
        rpath=$(recipe_path "$pkg") || {
            fetch_remote_recipe "$pkg" "$REPO_CONTEXT"
            rpath=$(recipe_path "$pkg")
        }
        
        # Get version
        recipe_ver=$(cat "$rpath/version" 2>/dev/null || echo "unknown")
        
        # Build to store
        build_to_store "$pkg" "$recipe_ver" "$rpath"
    else
        # Use legacy installation
        info "Using legacy installation for $pkg"
        build_from_recipe_enhanced "$pkg" "$force"
    fi
}

# --rollback
handle_rollback() {
    rollback_profile "default"
}

# --list-generations
handle_list_generations() {
    list_generations_store "default"
}

# --switch-generation N
handle_switch_generation() {
    gen="$1"
    [ -z "$gen" ] && err "Generation number required"
    switch_to_generation "default" "$gen"
}

# --gc
handle_gc() {
    dry_run="${1:-0}"
    collect_garbage_store "$dry_run"
}

# --store-info
handle_store_info() {
    info "╔════════════════════════════════════════════════════════════════╗"
    info "║                      Store Information                         ║"
    info "╚════════════════════════════════════════════════════════════════╝"
    
    printf "Store location:     %s\n" "$ASTRAL_STORE"
    printf "Profile directory:  %s\n" "$ASTRAL_PROFILES"
    printf "Store mode:         %s\n" "$USE_STORE_MODE"
    
    # Count store paths
    store_count=$(find "$ASTRAL_STORE" -maxdepth 1 -type d | wc -l)
    store_count=$((store_count - 1))  # Exclude store dir itself
    
    printf "\nStore contents:     %d packages\n" "$store_count"
    
    # Store size
    if [ -d "$ASTRAL_STORE" ]; then
        store_size=$(du -sh "$ASTRAL_STORE" 2>/dev/null | cut -f1)
        printf "Store size:         %s\n" "$store_size"
    fi
    
    # Current generation
    current=$(get_current_generation "default")
    printf "\nActive generation:  %d\n" "$current"
}

# --- ENTRY / CLI PARSING ---

# Require root for all operations
if [ "$(id -u)" -ne 0 ]; then
    err "Astral must be run as root (via sudo or doas)."
fi

# --- Global Option Parsing ---
while [ $# -gt 0 ]; do
    case "$1" in
        --dir)
            [ $# -lt 2 ] && err "Missing argument for $1"
            INSTALL_ROOT="$2"
            shift 2
            ;;
        --dir=*)
            INSTALL_ROOT="${1#*=}"
            shift
            ;;
        -f|--force)
            FORCE_BUILD=1
            shift
            ;;
        -n|--dry-run)
            DRY_RUN=1
            shift
            ;;
        -V|--version)
            astral_version
            ;;
        --)
            shift
            break
            ;;
        -*) # start of command
            break
            ;;
        *)
            break
            ;;
    esac
done

if [ $# -lt 1 ]; then usage; exit 1; fi

if [ "$INSTALL_ROOT" != "/" ]; then
    INSTALL_ROOT="${INSTALL_ROOT%/}"
    info "Global: Installation root set to: $INSTALL_ROOT"
fi

acquire_lock
trap release_lock EXIT
ensure_default_config
ensure_default_virtuals
ensure_default_mask
load_config

case "$1" in
-S|--Sync)
    [ $# -gt 1 ] || err "package name required"
    VISITED_PACKAGES=""
    
    # Use store-based installation if enabled
    if [ "$USE_STORE_MODE" = "yes" ]; then
        sync_pkg_with_store "$2" "$FORCE_BUILD"
    else
        sync_pkg_recursive "$2" "$FORCE_BUILD" 1
    fi
    
    FORCE_BUILD=0
    ;;

-C|--Compile)
    [ $# -gt 1 ] || err "package name required"
    VISITED_PACKAGES=""
    build_from_recipe_enhanced "$2" "$FORCE_BUILD"
    FORCE_BUILD=0
    ;;

-Re|--resume)
    [ $# -gt 1 ] || err "package name required"
    resume_build "$2"
    ;;

-SA|--Sync-Asura)
    [ $# -gt 1 ] || err "package name required"
    VISITED_PACKAGES=""
    sync_pkg_asura "$2" "$FORCE_BUILD" 1 
    FORCE_BUILD=0
    ;;

--Upgrade-All|-UA)
    upgrade_all
    ;;

  -u|--Update)
    repo="$2"
    shift 2
    update_repo "$repo"
    ;;

  -s|--Search)
    [ $# -gt 1 ] || err "package name required"
    search_pkg "$2"
    ;;

  -R|--Remove)
    [ $# -gt 1 ] || err "package name required"
    remove_pkg "$2"
    ;;

  -r|--RemoveDep)
    [ $# -gt 1 ] || err "package name required"
    removedep_pkg "$2"
    ;;

  -Cc|--Clean-Cache)
    clean_cache
    ;;

  -U|--self-update)
    self_update "${2:-main}"
    ;;

  --info|-I)
    [ $# -gt 1 ] || err "package name required"
    show_pkg_info "$2"
    ;;

  --inspect|-Ins)
    [ $# -gt 1 ] || err "package name required"
    r=$(recipe_path "$2") || err "recipe not found for $2"
    info "--- Files in Recipe Directory: $r ---"
    if [ -d "$r" ]; then
      ls -la "$r"
      [ -f "$r/info" ] && { info "\n--- PACKAGE INFO ($2) ---\n"; cat "$r/info"; }
      [ -f "$r/build" ] && { info "\n--- BUILD SCRIPT HEAD ($2) ---\n"; sed -n '1,20p' "$r/build"; }
    else
      info "--- Single Recipe File Content ($2) ---\n"
      sed -n '1,20p' "$r"
    fi
    ;;

  --list-installed|-ll)
    list_installed
    ;;
-D|--Deps)
    [ $# -gt 1 ] || err "package name required"
    show_deps "$2"
    ;;

-Dc|--DepCheck)
    check_system_deps
    ;;

--config)
    info "=== Astral Configuration ==="
    printf "Config File:      %s\n" "$CONFIG_FILE"
    printf "USE_FLAGS:        %s\n" "$USE_FLAGS"
    printf "CFLAGS:           %s\n" "$CFLAGS"
    printf "MAKEFLAGS:        %s\n" "$MAKEFLAGS"
    printf "CCACHE_ENABLED:   %s\n" "$CCACHE_ENABLED"
    printf "BINPKG_ENABLED:   %s\n" "$BINPKG_ENABLED"
    printf "FEATURES:         %s\n" "$FEATURES"
    ;;

  -V|--Version)
    astral_version
    ;;

  --https://www.youtube.com/watch?v=2EDcoWKH25o)
    echo "Flash Me Back - Camemellia. Peak btw"
    ;;

  --727|--whenyouseeit|--whenyoufuckingseeit|-WYSI|-WYFSI|--Arieu|--arieu)
    echo "727 WYSI WYFSI 727 WYFSI WYFSI"
    ;;

--rebuild-index|-RI)
    rebuild_files_index
    ;;

    -v|--verbose)
    VERBOSE=1
    export VERBOSE
    shift
    ;;

--show-env|-SE)
    info "=== Build Environment ==="
    printf "CFLAGS:   %s\n" "$CFLAGS"
    printf "CXXFLAGS: %s\n" "$CXXFLAGS"
    printf "LDFLAGS:  %s\n" "$LDFLAGS"
    printf "MAKEFLAGS: %s\n" "$MAKEFLAGS"
    ;;

--preview|-p)
    [ $# -gt 1 ] || err "package name required"
    pkg=$(sanitize_pkg_name "$2")
    preview_install "$pkg"
    ;;

--why|-w)
    [ $# -gt 1 ] || err "package name required"
    pkg=$(sanitize_pkg_name "$2")
    show_why_installed "$pkg"
    ;;

--world|-W)
    list_world
    ;;

--autoremove|--depclean)
    autoremove_orphans
    ;;

--list-virtuals)
    info "=== Virtual Packages ==="
    for virt in "$VIRTUALS_DIR"/*; do
        [ -f "$virt" ] || continue
        virt_name=$(basename "$virt")
        info "virtual/$virt_name:"
        grep -v '^#' "$virt" | grep -v '^[[:space:]]*$' | while IFS= read -r provider; do
            if is_pkg_installed "$provider" || check_host_dependency "$provider"; then
                info "  ✓ $provider"
            else
                info "  ✗ $provider"
            fi
        done
    done
    ;;

--mask)
    [ $# -gt 1 ] || err "package spec required (pkg or pkg >= ver)"
    shift
    echo "$*" >> "$MASK_FILE"
    info "Masked: $*"
    ;;

 --host-check)
     [ $# -gt 1 ] || err "package name required"
     test_host_dependency "$2"
     exit 0
     ;;

 --host-deps)
     show_host_deps
     exit 0
     ;;

--unmask)
    [ $# -gt 1 ] || err "package name required"
    pkg="$2"
    temp=$(mktemp)
    grep -v "^$pkg" "$MASK_FILE" > "$temp" 2>/dev/null || true
    mv "$temp" "$MASK_FILE"
    info "Unmasked: $pkg"
    ;;

 --ccache-stats)
     show_ccache_stats
     ;;

 --ccache-clear)
     clear_ccache
     ;;

     --rollback)
    handle_rollback
    ;;

--list-generations|-lg)
    handle_list_generations
    ;;

--switch-generation|-sg)
    [ $# -gt 1 ] || err "generation number required"
    handle_switch_generation "$2"
    ;;

--gc|--garbage-collect)
    dry_run=0
    [ "$2" = "--dry-run" ] && dry_run=1
    handle_gc "$dry_run"
    ;;

--store-info|-si)
    handle_store_info
    ;;

--enable-store)
    info "Enabling store-based package management..."
    sed -i 's/USE_STORE_MODE=.*/USE_STORE_MODE="yes"/' "$CONFIG_FILE"
    info "Store mode enabled. Future installations will use /var/lib/astral/store"
    init_profile "default"
    ;;

--disable-store)
    info "Disabling store-based package management..."
    sed -i 's/USE_STORE_MODE=.*/USE_STORE_MODE="no"/' "$CONFIG_FILE"
    info "Store mode disabled. Using legacy installation."
    ;;

  *|-*|--*)
    echo "Error: Unknown command or option '$1'" >&2
    usage
    exit 1
    ;;

esac
